## 场景问题

### 一、负载均衡

#### 负载均衡的算法有哪些

 **轮询**：负载均衡系统接收到请求后，**按照顺序轮流分配给服务器**。这种方式非常简单，只管按顺序分配，至于服务器当前负载情况、硬件能力等都不关心，只要服务器还能工作，就可以分配，除非服务器挂了。
 **加权轮询**：是轮询方式的一种改进，轮询方式是无差别分配，但实际服务器的处理能力是有差异的，所以需要区别对待。**为服务器设置权值，权值高的就多分配点**。
 **负载最低优先**：将任务分配给当前负载最低的服务器。例如 LVS 可以根据“连接数”判断服务器状态，NGINX 可以根据“HTTP请求数”来判断。这种方式比轮询高级很多，可以感知服务器的状态了，但其复杂度也大大提高了，要收集统计服务器的负载信息。
 **性能最优**：优先将任务分配给**处理速度最快的服务器**，来达到最快响应客户端的目的。此方式也是感知服务器的状态，标准是**响应时间**。需要收集分析服务器的响应时间，这个工作本身消耗也不小，所以采用**采样**的方式，不统计所有任务的响应时间，统计一个周期（例如 10秒/1分钟/5分钟）内的状态。优缺点与负载最低优先相同。
 **Hash**：**对请求中的关键信息（如IP）进行hash计算**，hash 值相同的请求分配到同一台服务器，例如业务中希望同一用户的请求都由同一台服务器来处理。

#### 一致性哈希算法

**普通的服务器哈希算法：**如果你有 *n* 个缓存服务器，*服务器索引 = 哈希(键) % N*，其中 *N* 是服务器池的大小。当新的服务器被添加，或者现有的服务器被移除时，大多数键都被重新分配了，这意味着，大多数缓存客户端将连接到错误的服务器来获取数据，导致了一场缓存未命中的风暴。

**一致性哈希：**一致性哈希是一种特殊的哈希，使得当哈希表大小改变且使用一致性哈希时，平均只有 k/n 个键需要被重新映射，其中 k 是键的数量，n 是槽位的数量。相比之下，在大多数传统哈希表中，数组槽位数量的变化导致几乎所有的键都需要被重新映射。

##### 哈希环

- 使用均匀分布的哈希函数将服务器和键映射到环上。
- 要找出键映射到哪个服务器，从键位置开始顺时针方向找到环上的第一个服务器。

![image-20230520221817073](https://gitee.com/xu_zuyun/picgo/raw/master/img/1f9d58cc2f204c4fb073a205c517d621.png)

使用上述逻辑，添加新服务器只需要重新分配一部分键。

问题：服务器可能会被添加或移除，环上的键分布可能非均匀。

##### 虚拟节点

虚拟节点是指实际节点，每个服务器在环上都由多个虚拟节点表示。随着虚拟节点数量的增加，键的分布变得更加均衡。这是因为随着虚拟节点数量的增加，标准差变得更小，导致数据分布均衡。然而，我们需要更多的空间来存储虚拟节点的数据。这是一个权衡，我们可以调整虚拟节点的数量以适应我们的系统需求。

![image-20230520221923607](https://gitee.com/xu_zuyun/picgo/raw/master/img/c618b83889b247888100b390fc328286.png)

### 二、手机扫二维码登陆的原理

![字节二面：扫码登录的原理](https://gitee.com/xu_zuyun/picgo/raw/master/img/v2-23efbeaf98a5e66775635b01e7801b4c_1440w.png)

##### 为什么用临时token？

临时token与token一样，它也是一种身份凭证，不同的地方在于它只能用一次，用过就失效。同时防止被坏人拦截token去冒充登录（token和设备是绑定的，故攻击者获取了手机长期token也无法在新设备上使用）

##### 为什么使用多次token？

以此确保扫码，登录两步操作是同一部手机端发出的。

### 三、分布式系统ID生成

**唯一性：**由于分布式系统包含多个节点，需要确保在不同的服务器、地理位置或时间点上创建的ID是全局唯一的，以便能够无歧义地识别和引用特定的数据或对象。

**去中心化：**为了高效率和可扩展性，分布式系统往往要求去中心化操作，这意味着每个节点应该能够独立生成ID，而不依赖于中央机构或服务。这减少了网络开销、避免了单点故障，并提升了系统整体的可用性。

**有序性：**某些应用场景可能需要ID具备一定的有序性，例如，一个增长的ID可以帮助保持数据存储在数据库中的顺序，从而优化检索速度。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/format,png-20240111145209266.png)

雪花算法的原理就是生成一个的 64 位比特位的 long 类型的唯一 id。

- 最高 1 位固定值 0，因为生成的 id 是正整数，如果是 1 就是负数了。
- 接下来 41 位存储毫秒级时间戳，2^41/(1000*60*60*24*365)=69，大概可以使用 69 年。
- 再接下 10 位存储机器码，包括 5 位 datacenterId 和 5 位 workerId。最多可以部署 2^10=1024 台机器。
- 最后 12 位存储序列号。同一毫秒时间戳时，通过这个递增的序列号来区分。即对于同一台机器而言，同一毫秒时间戳下，可以生成 2^12=4096 个不重复 id。

注意：依赖服务器时间，服务器时钟回拨时可能会生成重复 id。算法中可通过记录最后一个生成 id 时的时间戳来解决，每次生成 id 之前比较当前服务器时钟是否被回拨，避免生成重复 id。

##### 为什么要用雪花ID？

- **数据库自增 ID** 只适用于单机环境，但如果是分布式环境，是将数据库进行分库、分表或数据库分片等操作时，那么数据库自增 ID 就有问题了。

- **UUID** 内容很长，但没有业务含义，就是一堆看不懂的“字母”。UUID 是字符串类型，而字符串类型在数据库的查询中效率很低。

### 四、布隆过滤器

在十亿级别用户中检查用户名是否存在？            

**布隆过滤器**（`Bloom Filter`）是一**种数据结构**，用于快速检查一个元素是否存在于一个大型数据集中，通常用于在某些情况下快速过滤掉不可能存在的元素，以减少后续更昂贵的查询操作。布隆过滤器的主要优点是它可以提供快速的查找和插入操作，并且在内存占用方面非常高效。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/c75956be47c24514ba6a150af139e00d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

布隆过滤器的核心思想是使用一个位数组（`bit array`）和一组哈希函数。

- **位数组（Bit Array）** ：布隆过滤器使用一个包含大量位的数组，通常初始化为全0。每个位可以存储两个值，通常是0或1。这些位被用来表示元素的存在或可能的存在。
- **哈希函数（Hash Functions）** ：布隆过滤器使用多个哈希函数，每个哈希函数可以将输入元素映射到位数组的一个或多个位置。这些哈希函数必须是独立且具有均匀分布特性。

那么具体是怎么做的呢？

- **添加元素**：如上图所示，当将字符串“`xuyang`”，“`alvin`”插入布隆过滤器时，通过多个哈希函数将元素映射到位数组的多个位置，然后将这些位置的位设置为1。
- **查询元素**：当要检查一个元素是否存在于布隆过滤器中时，通过相同的哈希函数将元素映射到位数组的相应位置，然后检查这些位置的位是否都为1。如果有任何一个位为0，那么可以确定元素不存在于数据集中。但如果所有位都是1，元素可能存在于数据集中，但也可能是误判。

```java
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;

public class BloomFilterExample {
    public static void main(String[] args) {
        JedisPoolConfig poolConfig = new JedisPoolConfig();
        JedisPool jedisPool = new JedisPool(poolConfig, "localhost", 6379);

        try (Jedis jedis = jedisPool.getResource()) {
            // 创建一个名为 "usernameFilter" 的布隆过滤器，需要指定预计的元素数量和期望的误差率
            jedis.bfCreate("usernameFilter", 10000000, 0.01);
            
            // 将用户名添加到布隆过滤器
            jedis.bfAdd("usernameFilter", "alvin");
            
            // 检查用户名是否已经存在
            boolean exists = jedis.bfExists("usernameFilter", "alvin");
            System.out.println("Username exists: " + exists);
        }
    }
}
```

**优点：**

- **节约内存空间**，相比使用哈希表等数据结构，布隆过滤器通常需要更少的内存空间，因为它不存储实际元素，而只存储元素的哈希值。如果以 0.001 误差`概`率存储 `10` 亿条记录，只需要 `1.67 GB` 内存，对比原来的`20G`，大大的减少了。
- **高效的查找**， 布隆过滤器可以在常数时间内`（O(1)）`快速查找一个元素是否存在于集合中，无需遍历整个集合。

**缺点：**

- **误判率存在**：布隆过滤器在判断元素是否存在时，有一定的误判率。这意味着在某些情况下，它可能会错误地报告元素存在，但不会错误地报告元素不存在。
- **不能删除元素**：布隆过滤器通常不支持从集合中删除元素，因为删除一个元素会影响其他元素的哈希值，增加了误判率。

##### 布隆过滤器为什么要求多个哈希值？

使用多个哈希函数的原因是增加随机性，这样每个元素都会影响位数组中多个位置。如果只使用一个哈希函数，所有元素影响的位置就少了，从而更容易发生冲突，导致误报率上升。

##### 布隆过滤器你怎么设置的长度？

布隆过滤器的长度（位数组的大小），通常根据预期要存储的元素数量（n）和可接受的误判率（p）来计算，以及哈希函数的数量（k）计算得到

### 五、谈谈SSO单点登录的设计实现

单点登陆：学校的网站，有很多个系统，迎新系统，教务系统，网课系统，只需要登录一次就能在各个系统中被认定为登录状态。

#### Cookie共享传播状态

认证中心和其他系统是在一个域名下的，认证中心为父域名(jwxt.com)，其他系统是子域名(yx.jwxt.com)，或者是同一IP不同端口的情况，我们的服务端通过cookie去判断是否登录。

在认证中心登录成功的时候设置Cookie，**domin**要设置为父域名(.jwxt.com)，设置**SameSite**，此后子域名的系统也有了Cookie。

#### Session共享

使用Session共享技术，将Session信息存储在一个外部存储中，比如Redis、MongoDB等，从而实现多个应用程序之间的Session共享。使用一些现成的框架来实现Session共享，比如Spring Session、Apache Shiro。

- 数据库共享：将session存储在数据库中，不同的应用服务器通过访问同一数据库来实现session共享。
- Cookie共享：将session ID存储在cookie中，不同的应用服务器通过访问同一域名下的cookie来实现session共享。
- 缓存共享：将session存储在缓存中，不同的应用服务器通过访问同一缓存来实现session共享。常用的缓存系统有Redis、Memcached等。

#### Oauth2

基于OAuth2.0的单点登录：OAuth2.0是一种授权框架，可以用于实现单点登录。用户在第一次登录时，服务器会将用户的授权信息存储在OAuth2.0服务器中。当用户访问其他应用程序时，这些应用程序会向OAuth2.0服务器请求授权信息，如果授权信息有效则认为用户已经登录。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/v2-83662b2b5f33ebbd63124cc590b91673_1440w.webp)

### 五、实现文件上传

以nginx为例：

- 其默认允许1MB以内的文件
- 超过1MB的文件，需要设置`client_max_body_size`放开体积限制，但服务器的存储和网络带宽压力都会非常大

思想

- 将大文件分割成多个文件块
- 逐个上传文件块
- 服务端将文件块顺序合并成完整文件

流程

- 检查一下文件的格式、大小等等信息并根据文件信息生成文件的唯一标识（如 SHA-256）。
- 将需要上传的文件按照一定的分割规则，分割成相同大小的分片，例如将一个 100MB 的文件切割成相等大小的 5 份，每份 20MB；
- 初始化一个分片上传任务，返回本次分片上传的唯一标识（后续可以通过该唯一标识定位该次分片上传任务，可实现手动暂停和开始上传）；
- 每个分片在发送前，客户端会计算其哈希值（如 SHA-256），并将这个哈希值与分片一起发送给服务器；
- 按照一定的策略（串行或并行）发送各个分片；
- 服务器接收到分片后，会重新计算分片的哈希值，并与客户端发送的哈希值进行比对；
- 如果哈希值匹配，则认为该分片有效，服务器会存储该分片并等待其他分片的到来；如果哈希值不匹配，则认为该分片无效，说明该文件此次上传之前可能被修改过；
- 所有分片发送完成后，服务端会进行分片的合成，以得到原始文件。
- 再计算合并后的原始文件的唯一标识，与客户端发送的唯一标识进行对比，一致则说明此次文件上传没问题。

#### Java上传

```java
package com.example.demo.controller;

import cn.dev33.satoken.annotation.SaCheckLogin;
import com.example.demo.common.Result;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.multipart.MultipartFile;

import javax.servlet.ServletOutputStream;
import javax.servlet.http.HttpServletResponse;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.util.UUID;

@Slf4j
@RestController
@RequestMapping("/common")
public class CommonController {

    @Value("${takeOutFile.fileLocaltion}")
    private String basePath ;

    @PostMapping("/upload")
    public Result<String> upload(MultipartFile file){
        //这里的file只是一个临时的文件存储，临时存储到某一个位置，然后待接收完毕后再转存到目标位置上，然后再把这个临时文件删除
        //截取文件后缀
        String suffix = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf('.'));
        //生成UUID
        String randomUUID = UUID.randomUUID().toString();
        //拼接文件最后名称，结果为文件本体名字+UUID+后缀
        String fileName = file.getOriginalFilename() + randomUUID + suffix;

        //保证存储的位置有这个文件夹
        File dir = new File(basePath);
        if (!dir.exists()) {
            //目标存储位置不存在，就创建一个文件夹
            dir.mkdirs();
        }

        try {
            //转存文件到指定位置+文件的名称全拼
            file.transferTo(new File(basePath+fileName));
        } catch (IOException e) {
            e.printStackTrace();
        }
        //把文件的名字上传回去，方便后续回显读取路径
        return Result.success(fileName);
    }

    /**
     * 文件回显接口
     * @param httpServletResponse 响应对象
     * @param name 上传的文件名称
     * @throws IOException IO异常
     */
    @GetMapping("/download")
    public void fileDownload(HttpServletResponse httpServletResponse, String name) throws IOException {
        //把刚刚存的文件读取到内存中，准备回显
        FileInputStream fileInputStream = new FileInputStream(new File(basePath+name));
        log.info("文件存储的位置为："+basePath+name);
        //把读取到内存中的图片用输出流写入Servlet响应对象里
        ServletOutputStream servletOutputStream = httpServletResponse.getOutputStream();

        //可选项，选择响应类型
        httpServletResponse.setContentType("image/jpeg");

        //用byte数组写入，注意是小写b，不是大写，大写就是包装类了
        byte[] fileArray = new byte[1024];
        int length=0;
        try {
            //只要没读到数组的尾部就一直读下去，这部分是IO的内容
            while ((length=fileInputStream.read(fileArray))!=-1) {
                //写入响应流，从0开始，写入到数组末尾长度
                servletOutputStream.write(fileArray, 0, length);
                //把流里的东西挤出来
                servletOutputStream.flush();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }finally {
            //关闭流
            fileInputStream.close();
            servletOutputStream.close();
        }
        return;
    }
}
```

### 六、防止非法盗链

#### Referer字段

通过检查HTTP头部中的Referer字段，判断请求来源是否合法。只允许来自特定域名或IP地址的请求才能访问资源。这种方法较容易实施，不过存在一定的伪造风险。

referer字段：表示页面从哪里跳转而来。例如：A跳转到了B，在B中查看请求头时就可以看到Referer字段的值为A地址。

- 1、网页中的超链接。
- 2、用户发送表单。
- 3、网页加载静态资源；例如：图片、脚本、样式等

```java
public class RefererFilter implements Filter {

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
		System.out.println("初始化方法...");
    }
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
 	    System.out.println("拦截请求...");
 	    
        HttpServletRequest req = (HttpServletRequest) request;
        HttpServletResponse res = (HttpServletResponse) response;
        //每次请求来源 （）
        String referer = req.getHeader("referer");
        //获取请求地址，返回当前页面所在的服务器的名字访问路径：http://127.0.0.1:8080/demo/ -> 返回：127.0.0.1
        String serverName = req.getServerName();
        
        System.out.println("referer:" + referer + "---serverName" + serverName);
        
        if (referer == null || !referer.contains(serverName)) {
            req.getRequestDispatcher("/static/images/error.png").forward(req, res);
            return;
        }
        //放行
        chain.doFilter(req, res);
    }
    @Override
    public void destroy() {
		System.out.println("销毁请求...");
    }
}
```

#### 携带自定义Token

为每次请求生成一个唯一的Token，并将其作为URL参数或者在HTTP头中发送。服务器验证此Token是否有效，并根据验证结果决定是否提供资源。

```php
// PHP代码示例，生成和验证Token
$secret = 'SECRET_KEY';
$token = md5($secret . $_SERVER['REMOTE_ADDR'] . date('Ymd'));

if ($_GET['token'] != $token) {
    header('HTTP/1.0 403 Forbidden');
    exit;
}
```

####  修改资源链接

定期更改资源的URL地址，使得旧的链接很快就会失效，从而减少盗链的可能性。这通常与CDN或者动态网站结合使用更为有效。

### 七、有哪些常用限流算法？

#### Leaky Bucket 漏桶

漏桶可理解为是一个限定容量的请求队列。想象有一个桶，有水（指请求或数据）从上面流进来，水从桶下面的一个孔流出来。水流进桶的速度可以是随机的，但是水流出桶的速度是恒定的。 当水流进桶的速度较慢，桶不会被填满，请求就可以被处理。 当水流进桶的速度过快时，桶会逐渐被填满，当水超过桶的容量就会溢出，即被丢弃。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/202309090040484.png)

#### Token Bucket 令牌桶

在令牌桶算法中，系统会以一个固定的速率向桶中添加令牌。当有请求（或数据包）到来时，会从桶中删除一定数量的令牌。如果桶中有足够的令牌，请求就可以立即处理； 如果桶中没有足够的令牌，请求就会被阻塞或丢弃，具体行为取决于具体的实现。 桶有容量限制，如果添加令牌时桶已满，新的令牌就会被丢弃。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/20220209161224.png)

```markdown
## 漏桶 (Leaky Bucket):
数据以固定的速率离开漏桶。
即使网络中没有数据传输，包也会以恒定的速率进行排队。
这导致数据输出具有很高的确定性。

## 令牌桶 (Token Bucket):
数据可以以任何速率进入桶内，只要桶内有令牌，数据就能以任意速率发送，直到达到网络最大速率。
允许某种程度的突发性，因为如果桶中有足够的令牌，数据可以快速发送。
相对来说，输出速率更加灵活。
```

#### Fixed Window 固定窗口

在一个固定的时间窗口内，只允许一定数量的请求。如果在这个时间窗口内的请求已经达到了限制，那么新的请求就会被拒绝，过了当前时间窗口后，会进入下一个时间窗口，并重置窗口内的请求数量，重新计算。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/20220209144040.png)

#### Sliding Window 滑动窗口

在固定窗口限流算法中，如果大量请求在一个时间窗口的边界附近到达，可能会造成瞬时的流量突增。 滑动窗口随着时间的推移，动态统计请求量，避免了在窗口边界附近的流量突增。

### 八、服务器集群中的session共享方案有哪些？

#### 1、session复制同步方案

解决方式:每个节点都复制其他节点的session

```markdown
## 优点：
web-server(tomcat)不需要额外开发，只需搭建tomcat集群即可,修改配置文件
## 缺点：
数据传输占用带宽,内存限制
```

#### 2、cookie客户端存储

解决方式:session存储在客户端的cookie中
```markdown
## 优点:
服务器不需存储session，用户保存自己的 session信息到cookie中。节省服务端资源
## 缺点:
1.每次http请求，携带用户在cookie中的完整信息，浪费网络带宽
2.session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患
3.session数据放在cookie中，cookie有长度限制4K，不能保存大量信息
```

#### 3、nginx ip_hash一致性

解决方式:固定的用户固定的请求一台服务器
```markdown
## 优点：
只需要改nginx配置，不需要修改应用代码
负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的
可以支持web-server水平扩展（session同步法是不行的，受内存限制）
## 缺点:
服务器重启可能导致部分session丢失，影响业务，如部分用户需要重新登录
如果服务器水平扩展，rehash后session重新分布，会有用户路由不到正确的session
但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用
```

#### 4、统一存储

解决方式:后端统一存储session
```markdown
## 优点：
没有安全隐患；
可以水平扩展，数据库/缓存 水平切分即可；
服务器重启或者扩容都不会有session丢失。
## 缺点:
增加了一次网络调用；
如将所有的getSession方法替换为从Redis查数据的方式。
缺点可以用SpringSession完美解决。
```

### 九、零拷贝技术

Netty 用到了零拷贝来大幅提升网络吞吐量

正常流程：4次拷贝，4次用户态和内核态之间的切换

![非DMA非零拷贝 (1).png](https://gitee.com/xu_zuyun/picgo/raw/master/img/6fe8074c922b43a3b190ea000087da67~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

1. 应用进程向系统申请读磁盘的数据，这时候程序从用户态切换成内核态。
2. 系统也就是 linux 系统得知要读数据会通知 DMA 模块要读数据，这时 DMA 从磁盘拉取数据写到系统内存中。
3. 系统收到 DMA 拷贝的数据后把数据拷贝到应用内存中，同时把程序从内核态变为用户态。
4. 应用内存拿到从应用内存拿到数据后，会把数据拷贝到系统的 Socket 缓存，然后程序从用户态切换为内核态。
5. 系统再次调用 DMA 模块，DMA 模块把 Socket 缓存的数据拷贝到网卡，从而完成数据的发送，最后程序从内核态切换为用户态。

#### MMAP + write

```c
buf = mmap(file,length) 
write(socket,buf,length)
  // 所谓的 MMAP， 其实就是系统内存某段空间和用户内存某段空间保持一致，也就是说应用程序能通过访问用户内存访问系统内存
```

- 应用进程通过接口调用系统接口 MMAP，并且进程从用户态切换为内核态。
- 系统收到 MMAP 的调用后用 DMA 把数据从磁盘拷贝到系统内存，这时是第1次数据拷贝。由于这段数据在系统内存和应用内存是共享的，数据自然就到了应用内存中，这时程序从内核态切换为用户态。
- 程序从应用内存得到数据后，会调用 write 系统接口，这时第2次拷贝开始，具体是把数据拷贝到 Socket 缓存，而且用户态切换为内核态。
- 系统通过 DMA 把数据从 Socket 缓存拷贝到网卡。
- 最后，进程从内核态切换为用户态。

这样做到收益是`减少了一次拷贝`，`但是用户态和内核态仍然是4次切换`。

#### sendfile

![零拷贝之sendfile.png](https://gitee.com/xu_zuyun/picgo/raw/master/img/a08835b5b0cd41d7aaca88d4089f3c08~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

1. 应用进程调用系统接口 sendfile，进程从用户态切换完内核态。
2. 系统接收到 sendfile 指令后，通过 DMA 从磁盘把数据拷贝到系统内存。
3. 数据到了系统内存后，CPU 会把数据从系统内存拷贝到 socket 缓存中。
4. 通过 DMA 拷贝到网卡中。
5. 最后，进程从内核态切换为用户态。

#### 零拷贝

1. 应用进程调用系统接口 sendfile，进程从用户态切换完内核态。
2. 系统接收到 sendfile 指令后，通过 DMA 从磁盘把数据拷贝到系统内存。
3. 数据到了系统内存后，CPU 会把文件描述符和数据长度返回到 socket 缓存中（注意这里没有拷贝数据）。
4. 通过 SG-DMA 把数据从系统内存拷贝到网卡中。
5. 最后，进程从内核态切换为用户态。

![真正的零拷贝.png](https://gitee.com/xu_zuyun/picgo/raw/master/img/c3ace07d37cb4157bc27435369549eeb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

`零拷贝在用户态和内核态之间的切换是2次，拷贝是2次`，在内存之间没有拷贝，大大减少了切换次数和拷贝次数,而且全程没有 CPU 参与数据的拷贝。

```markdown
## SG-DMA
在通常情况下，DMA 操作是在一个连续的内存块上执行的。然而，在实际应用中，所需的数据可能是分散的，即分布在物理内存的多个不同区域。Scatter-Gather DMA 就是为了解决这个问题而设计的：

- 分散（Scatter）：指的是从内存的多个不连续位置读取数据块，并"分散"到连续的硬件缓冲区中，或者相反，将数据从硬件的连续缓冲区写入到内存的分散区域。

- 聚集（Gather）：则是指将来自多个源的数据“聚集”起来，组合成一个大的数据块，以便连续地通过 DMA 传输。

为实现这一过程，操作系统通常会维护一个描述符表或链表，列出所有分散内存区块的地址和大小。DMA 控制器使用这个表来了解每个数据块的位置，并按正确的顺序将它们聚集起来进行传输。

Scatter-Gather DMA 在需要高效处理大量分散数据的场景下非常有用，比如在网络通信、文件系统管理和音视频数据流处理中。它消除了额外的数据拷贝步骤，因为它允许直接在分散的内存区块上操作，从而减少了延迟，提高了吞吐量，并减轻了 CPU 负担。
```

### 十，token刷新技术

#### Access Token 和 Refresh Token的区别

1. 用途
   - **Access Token**：用于访问受保护的资源。当应用程序想要请求用户数据时，需要提供有效的access token来获得授权。
   - **Refresh Token**：用于在access token过期后获取新的access token，而不需要用户重新登陆。
2. 生命周期
   - **Access Token**：通常具有较短的有效期限，通常范围从几分钟到几小时不等。短周期可以降低因token泄露导致的安全风险。
   - **Refresh Token**：通常具有更长的有效期，可能持续数天、数周或者更长时间，直到用户明确注销或者被撤销。
3. 安全性
   - **Access Token**：由于经常在客户端和服务器之间传输，可能会有泄露的风险。因此，它们的生命周期被设定为较短以减轻潜在的风险。
   - **Refresh Token**：很少传输，通常只在**客户端和授权服务器**之间使用，并且通常只通过安全的后端通道进行。因此，它们的安全性相对较高。
4. 格式和内容
   - **Access Token**：可以是不透明的字符串，也可以是具有一定结构的令牌，如JSON Web Tokens (JWT)。结构化的token可能包含关于用户的信息和token的有效期。
   - **Refresh Token**：通常是不透明的字符串，不包含任何可读信息。它们的唯一目的是用来交换新的access token。

#### 流程

> 1. **用户身份验证**: 用户首先通过提供用户名和密码或其他认证机制（如多因素认证）来登录应用程序。
> 2. **获取Access Token和Refresh Token**: 认证成功后，授权服务器会向客户端（可能是一个Web应用、移动应用或服务器应用）发放一个access token和一个refresh token。Access token用于访问受保护的资源，而refresh token将用于后续获取新的access tokens。
> 3. **使用Access Token访问资源**: 客户端使用收到的access token向资源服务器请求访问受保护的资源。如果token有效，资源服务器将允许访问。
> 4. **Access Token过期**: Access token一般有较短的有效期限，比如一小时。一旦过期，任何进一步的资源请求都会被资源服务器拒绝。
> 5. **使用Refresh Token获取新的Access Token**: 当access token过期后，客户端可以使用之前保存的refresh token请求授权服务器颁发一个新的access token。这个过程不需要用户重新登录，从而提供了更好的用户体验。
> 6. **授权服务器验证Refresh Token**: 授权服务器收到请求后，会验证refresh token的有效性。如果验证成功，并且refresh token没有被撤销，服务器将发放一个新的access token（以及可能的新refresh token）。

### 十一，百亿数据中找中位数

1. 桶/计数排序思想

   根据数据的特征，比如数据落在某个固定范围内，可以使用桶排序或计数排序的思想。通过统计每个桶内元素的数量，我们可以确定中位数所在的桶，然后在该桶内使用更精确的方法计算中位数。

2. 外部排序

   如果数据无法一次性装入内存，则可以使用外部排序。这个过程包括将数据分割成多个块，每个块单独排序并存储在外部存储器（如硬盘）上，再将这些有序的块合并来找出整体的中位数。

   ```markdown
   1. 分割数据
   将原始数据集分割成多个小块，称为“runs”或“chunks”。每个小块的大小应当适合放入内存中进行排序。
   
   2. 排序小块
   读取每个小块至内存，使用内部排序算法（如快速排序、堆排序等）对其进行排序。
   
   3. 存储排序后的小块
   将排序后的小块写回到外部存储（硬盘等）上。这样，硬盘上就有了多个有序的数据块。
   
   4. 归并排序
   使用N路归并排序算法，将所有有序的小块合并成一个完整有序的数据集。这个步骤通常涉及以下操作：
   
   创建一个优先队列（最小堆），初始化时将每个有序块的第一个元素加入。
   不断从优先队列（堆）中取出最小元素，并将该元素所在块的下一个元素加入队列。
   将取出的最小元素写入到最终的输出文件中。
   重复以上过程直到所有块中的元素都被处理。
   5. 输出最终结果
   最终，所有数据块中的元素都按顺序写入到最终输出文件中，完成总体的排序任务。
   
   外部排序的效率很大程度上取决于磁盘IO的速度以及归并阶段处理有序块的效率。在现代操作系统中，通常会使用缓冲区来减少磁盘IO次数，提高外部排序的速度。
   ```

3. MapReduce估算中位数

   - 将数字按范围（数位大小）分到不同的桶中

   - 每个分位桶排序计算得到一个局部中位数

   - 以中间两个桶的局部中位数为基础来估算全局中位数

### 十二，海量数据，求TopK问题

海量日志数据，提取出某日访问百度次数最多的那个IP，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。换言之，先映射，而后统计，最后排序。

具体分为以下3个步骤

> - 1.分而治之/hash映射
>   - 首先把这一天访问百度日志的所有IP提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如%1000，把整个大文件映射为1000个小文件。
> - 2.hash_map统计
>   - 当大文件转化成了小文件，那么我们便可以采用hash_map(ip, value)来分别对1000个小文件中的IP进行频率统计，再找出每个小文件中出现频率最大的IP。
> - 3.堆/快速排序
>   - 统计出1000个频率最大的IP后，依据各自频率的大小进行排序(可采取堆排序)，找出那个频率最大的IP，即为所求。
>
> 注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，只可能落在同一个文件中，不可能被分散的。

同样的，有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

解法：

> - 1.分而治之/hash映射
>   - 顺序读取文件，对于每个词x，取hash(x)%5000，然后把该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。当然，如果其中有的小文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。
> - 2.hash_map统计
>   - 对每个小文件，采用trie树/hash_map等统计每个文件中出现的词以及相应的频率。
> - 3.堆/归并排序
>   - 取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。

参考：https://www.cnblogs.com/xingyunblog/articles/9078808.html

### 十三、如何设计一个比较两篇文章相似度的算法？

局部敏感哈希（Locality-Sensitive Hashing，LSH）是一种用于快速相似性搜索的算法技术。该技术主要用于高维空间中的数据，其目标是为相似的对象生成相同或相近的哈希值，而对于不相似的对象则生成不同的哈希值。通过这种方式，LSH能够在大规模数据集中高效地执行近邻搜索任务。

```
特点：
局部敏感性：如果两个数据点相似，那么它们被哈希到相同桶中的概率会很高。
可调性：LSH家族通常有参数可以调整，以控制相似度与哈希碰撞概率之间的平衡。
```

simhash作为locality sensitive hash（局部敏感哈希）的一种：

- 其主要思想是降维，将高维的特征向量映射成低维的特征向量，通过两个向量的Hamming Distance来确定文章是否重复或者高度近似。

  其中，Hamming  Distance，又称汉明距离，在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。如此，通过比较多个文档的simHash值的海明距离，可以获取它们的相似度。

simhash算法分为5个步骤：分词、hash、加权、合并、降维，具体过程如下所述：

- 分词
  - 给定一段语句，进行分词，得到有效的特征向量，然后为每一个特征向量设置1-5等5个级别的权重（如果是给定一个文本，那么特征向量可以是文本中的词，其权重可以是这个词出现的次数）。例如给定一段语句：“CSDN博客结构之法算法之道的作者July”，分词后为：“CSDN 博客 结构 之 法 算法 之 道 的 作者 July”，然后为每个特征向量赋予权值：CSDN(4) 博客(5) 结构(3) 之(1) 法(2) 算法(3) 之(1) 道(2) 的(1) 作者(5) July(5)，其中括号里的数字代表这个单词在整条语句中的重要程度，数字越大代表越重要。
- hash
  - 通过hash函数计算各个特征向量的hash值，hash值为二进制数01组成的n-bit签名。比如“CSDN”的hash值Hash(CSDN)为100101，“博客”的hash值Hash(博客)为“101011”。就这样，字符串就变成了一系列数字。
- 加权
  - 在hash值的基础上，给所有特征向量进行加权，即W = Hash *  weight，且遇到1则hash值和权值正相乘，遇到0则hash值和权值负相乘。例如给“CSDN”的hash值“100101”加权得到：W(CSDN) = 100101_4 = 4 -4 -4 4 -4 4，给“博客”的hash值“101011”加权得到：W(博客)=101011_5 = 5  -5 5 -5 5 5，其余特征向量类似此般操作。
- 合并
  - 将上述各个特征向量的加权结果累加，变成只有一个序列串。拿前两个特征向量举例，例如“CSDN”的“4 -4 -4 4 -4  4”和“博客”的“5 -5 5 -5 5 5”进行累加，得到“4+5 -4+-5 -4+5 4+-5 -4+5 4+5”，得到“9 -9 1  -1 1”。
- 降维
  - 对于n-bit签名的累加结果，如果大于0则置1，否则置0，从而得到该语句的simhash值，最后我们便可以根据不同语句simhash的海明距离来判断它们的相似度。例如把上面计算出来的“9 -9 1 -1 1 9”降维（某位大于0记为1，小于0记为0），得到的01串为：“1 0 1 0 1 1”，从而形成它们的simhash签名。

### 十四、日常有哪些攻击手段以及相应的防护措施？

##### 1. 分布式拒绝服务攻击（DDoS，Distributed Denial of Service）

- **描述**：通过大量恶意流量使服务器或网络资源不可用。

  ```
  Volumetric Attacks（容量型攻击）：
  这类攻击试图耗尽目标网络的带宽，例如通过UDP洪泛（UDP flood）或ICMP洪泛（ICMP flood）。
  
  Protocol Attacks（协议攻击）：
  这些攻击目标是网络层或传输层的协议，比如SYN洪泛攻击（SYN flood）或Ping of Death，旨在消耗目标系统的处理能力。
  
  Application Layer Attacks（应用层攻击）：
  针对特定应用程序的攻击，如HTTP洪泛攻击，模仿正常用户行为但意图耗尽应用资源。
  ```

- **防范**：使用DDoS防护服务（如Cloudflare或AWS Shield）、配置适当的网络规则来过滤流量、保持冗余网络和资源。

##### 2. SQL注入

- **描述**：攻击者在SQL查询中注入恶意代码，从而控制数据库。
- **防范**：使用参数化查询、限制数据库权限、定期审计SQL查询。

##### 3. 交叉站点脚本（XSS，Cross-Site Scripting）

- **描述**：在用户浏览器上执行非经请求的脚本，窃取信息或者仿冒用户。

  1. **存储型 XSS (Stored XSS)** 存储型 XSS 攻击发生时，恶意脚本被永久地存储在目标服务器上，例如在数据库、消息论坛、访客日志、评论区等。当其他用户浏览到含有恶意脚本的页面时，就会受到攻击。
  2. **反射型 XSS (Reflected XSS)** 反射型 XSS 发生时，恶意脚本并不会存储在服务器上，而是通过用户点击一个恶意链接或提交表单触发的。该恶意脚本通常作为请求的一部分发送到服务器端，然后服务器端将其作为响应的一部分返回，并在用户的浏览器上执行。

  后果：

  - 盗取用户的 cookies 和会话令牌。
  - 对用户界面进行篡改。

- **防范**：对用户输入进行过滤和转义、设置HTTPOnly和Secure标志的Cookies、内容安全策略（CSP）。

##### 4. 会话劫持和固定会话攻击

- **描述**：攻击者尝试截获或接管用户的会话令牌来仿冒用户。

  操作方式：

  - 监听不安全的网络流量来捕获未加密的会话token。
  - 使用XSS攻击将用户的会话cookie发送到攻击者控制的服务器。

- **防范**：使用HTTPS、定期更换会话ID、实施合理的会话超时机制。

##### 5. 中间人攻击（MITM）

- **描述**：攻击者在通信双方之间截获或篡改数据。
- **防范**：始终使用加密协议（例如TLS/SSL）、公共Wi-Fi的VPN连接、端点认证。

### 十五、云原生技术

发展历程：

- 物理机部署：早期一般将应用程序直接部署到物理机上，部署方式简单，但是不能为应用程序定义资源和使用边界，很难合理的分配计算资源，应用程序之间会产生影响。
- 虚拟机部署：在一台物理机上运行多个虚拟机，每个虚拟机都是一个独立的环境，这会导致额外的操作系统开销。
- 容器化部署：容器化部署与虚拟机类似，不同点是容器之间共享操作系统，每个容器之间拥有自己的**文件系统、CPU、内存、进程空间**，应用程序需要的资源都被容器包装，并且和底层基础架构解耦，可以实现跨服务器跨操作系统进行部署。

云原生（Cloud Native）是一种构建和运行应用程序的方法，它充分利用了云计算的优势。"云原生"技术使得组织可以构建和运行可在公共云、私有云或混合云环境中无缝运作的应用程序。这种方法并不是指特定的技术或工具，而是一套技术理念和最佳实践的集合，旨在充分发挥现代云计算模型的潜力。

1. **容器化**：应用程序及其运行环境被封装在容器中。容器是轻量级的、可移植的、自给自足的软件执行环境，可以确保软件在不同的计算环境中以相同的方式运行。
2. **微服务架构**：应用被设计为一系列小型、独立的服务，每个服务负责执行单一业务功能。这些服务可以独立部署、扩展和管理。
3. **动态管理**：利用自动化系统进行资源的分配和优化，常见的有Kubernetes等容器编排平台。这些系统能够在多个服务器和环境中自动部署、维护和扩展容器化应用。
4. **敏捷性和持续交付**：云原生应用支持快速迭代开发和发布，促进持续集成/持续部署（CI/CD）的实践，从而加速产品上市时间并提高响应市场变化的能力。
5. **可伸缩性**：云原生应用能够根据负载自动扩展或收缩资源，从而有效地利用云资源，并对突然的流量变化做出快速响应。

流程：

> ### 步骤 1: 创建并容器化您的应用程序
>
> 首先，你需要有一个应用程序。我们以一个简单的 Node.js 应用为例，以下是 `app.js` 的代码：
>
> ```javascript
> const http = require('http');
> 
> const requestHandler = (request, response) => {
>     console.log(request.url);
>     response.end('Hello Kubernetes!');
> };
> 
> const server = http.createServer(requestHandler);
> 
> server.listen(8080, () => {
>     console.log(`Server is running on 8080`);
> });
> ```
>
> ### 步骤 2: 编写 Dockerfile
>
> 接着，为你的应用编写一个 Dockerfile 来构建一个 Docker 镜像。保存为 `Dockerfile` 文件：
>
> ```dockerfile
> # 使用 Node.js 官方镜像作为构建环境
> FROM node:14
> 
> # 创建 app 目录
> WORKDIR /usr/src/app
> 
> # 安装 app 依赖
> # 使用通配符确保 package.json 和 package-lock.json 都被复制
> # 在这个示例中，假设你已经有了一个 package.json 和相应的 package-lock.json
> COPY package*.json ./
> 
> RUN npm install
> 
> # 打包 app 源代码
> COPY . .
> 
> # 应用绑定的端口
> EXPOSE 8080
> 
> # 定义环境变量
> ENV NAME World
> 
> # 运行命令
> CMD [ "node", "app.js" ]
> ```
>
> ### 步骤 3: 构建 Docker 镜像
>
> 在包含 Dockerfile 的目录中执行以下命令来构建镜像：
>
> ```sh
> docker build -t my-nodejs-app .
> ```
>
> ### 步骤 4: 推送镜像到镜像仓库
>
> 假设你要将镜像推送到 Docker Hub，你需要给镜像打上标签并推送它：
>
> ```sh
> docker tag my-nodejs-app yourusername/my-nodejs-app:v1
> docker push yourusername/my-nodejs-app:v1
> ```
>
> ### 步骤 5: 编写 Kubernetes 配置
>
> 现在编写 Kubernetes 配置来定义如何在集群中运行镜像。创建一个名为 `deployment.yaml` 的文件：
>
> ```yaml
> apiVersion: apps/v1
> kind: Deployment
> metadata:
>   name: my-nodejs-app
> spec:
>   replicas: 2 # 你想要运行的副本数
>   selector:
>     matchLabels:
>       app: my-nodejs-app
>   template:
>     metadata:
>       labels:
>         app: my-nodejs-app
>     spec:
>       containers:
>       - name: my-nodejs-app
>         image: yourusername/my-nodejs-app:v1 # 替换成你的镜像名称
>         ports:
>         - containerPort: 8080
> ```
>
> 还可以创建一个 `service.yaml` 文件来定义外部访问您的应用程序的规则：
>
> ```yaml
> apiVersion: v1
> kind: Service
> metadata:
>   name: my-nodejs-service
> spec:
>   selector:
>     app: my-nodejs-app
>   type: LoadBalancer # 使用负载均衡器暴露服务
>   ports:
>     - protocol: TCP
>       port: 80
>       targetPort: 8080
> ```
>
> ### 步骤 6: 在 Kubernetes 中部署应用程序
>
> 最后，在 Kubernetes 集群上部署你的应用和服务：
>
> ```yaml
> kubectl apply -f deployment.yaml
> kubectl apply -f service.yaml
> ```
>
> 如果一切正常，你的 Node.js 应用现在应该是由两个副本组成的部署，并通过负载均衡器对外提供服务。
>
> 要检查部署情况，可以使用以下命令：
>
> ```sh
> kubectl get deployments
> kubectl get pods
> kubectl get services
> ```

### 十七、基于角色的访问控制模型（RBAC）

在 Casbin 中，策略规则通常存储在称为 "policy" 的表或文件中。这个 "rule" 表（或者称为 “policy storage”）是用来保存 Casbin 访问控制策略的细节信息。使用 SQL 语法表示：

```sql
CREATE TABLE casbin_rule (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    ptype VARCHAR(255) NOT NULL,
    v0 VARCHAR(255) NOT NULL,
    v1 VARCHAR(255) NOT NULL,
    v2 VARCHAR(255) DEFAULT NULL,
    v3 VARCHAR(255) DEFAULT NULL,
    v4 VARCHAR(255) DEFAULT NULL,
    v5 VARCHAR(255) DEFAULT NULL
);
```

- `id`：主键，唯一标识每条策略规则。
- `ptype`：策略类型，例如 `p` 表示策略 (policy)，`g` 表示角色继承关系 (grouping policy)。
- `v0` - `v5`：这些字段用来存储策略的参数。根据具体的 Casbin 模型和策略的复杂性，可以使用不同数量的参数，通常 v0 表示 subject（主体），v1 表示 object（对象），v2 表示 action（操作）。其余字段可用于存储其他条件、角色或权限等，具体取决于你的 Casbin 模型配置。

通常是一个三元素策略（subject, object, action）

- `v0` 可以是用户名或用户组。
- `v1` 可以是资源，例如文件、数据库表或者 URL。
- `v2` 可以是对该资源的操作，例如 read、write 或 delete。

![image-20240315141533608](https://gitee.com/xu_zuyun/picgo/raw/master/img/image-20240315141533608.png)

### 十八、如何设计幂等性？

- 1. 使用唯一标识符

  为每个操作请求分配一个唯一标识符（如 UUID 或其他形式的 token）。在执行操作之前，系统首先检查这个标识符是否已经存在，如果存在，则跳过操作；否则，进行操作并记录这个标识符。

- 2. 数据库约束

  利用数据库的唯一索引或主键约束来阻止重复的记录。例如，在数据库中插入记录时，如果记录的关键字段已经存在，数据库将拒绝新的插入操作。

- 3. 状态机

  对资源状态进行建模，并确保转换规则使得重复的操作不会改变资源的最终状态。例如，如果一个对象已经处于“已处理”状态，则不管再收到多少次处理请求，它都将保持“已处理”状态。

### 十九、内存映射

内存映射（Memory Mapping，简称 mmap）是一种在程序中处理文件的高效方式。这种技术允许程序将一个磁盘上的文件或其他对象直接映射到进程的地址空间中，使得开发人员可以像访问普通内存数组一样来操作这个文件，而不需要使用传统的文件读写操作如`read`和`write`。

当一个文件被内存映射后，操作系统会负责将文件内容加载到物理内存中，并为它在虚拟地址空间中提供一个直接的访问界面。对于这部分内存的读写操作，则通过内存访问指令直接完成，无需额外的系统调用，这能够显著提升文件读写操作的性能。

内存映射的优点包括：

1. **性能提升：** 内存映射文件的I/O操作可能比标准的文件I/O更快，因为它们利用了操作系统的页缓存以及潜在的懒加载机制。
2. **便捷的数据访问：** 映射之后的文件可以像普通的内存区域一样进行字节级别的随机访问。

### 二十、文件存储、块存储、对象存储

##### 文件存储 (File Storage)

- **概念**: 文件存储是一种基于文件和目录层次结构的存储方法。用户和应用程序可以通过操作系统提供的文件系统接口来保存、组织和检索数据。
- 特点
  - 提供了一个标准的文件导航系统，包括文件夹和子文件夹。
  - 支持文件级访问控制和权限管理。
  - 可以通过`网络共享协议`（例如NFS、SMB/CIFS）跨网络进行文件共享。
- 场景：文件服务器、HTML

##### 块存储 (Block Storage)

- **概念**: 块存储将存储卷分割成固定大小的块，每个块都可以独立地被当作硬盘来使用。操作系统可以格式化这些块并在其上安装文件系统。
- 特点
  - 每个存储块都像磁盘驱动器一样工作，可以单独格式化和挂载。
  - 提供了高性能的I/O处理，适合数据库、虚拟机文件系统等需要快速读写的场景。
  - 常见于SAN（存储区域网络）环境中，通常通过iSCSI、Fibre Channel等协议提供访问。
- 场景：数据库、高性能计算

##### 对象存储 (Object Storage)

- **概念**: 对象存储用于管理数据作为单独的单位，称为对象。每个对象包含数据本身、变量长度的元数据以及一个全球唯一的标识符（通常是URL）。
- 特点
  - 无需复杂的层次结构或文件系统；对象可以在扁平的地址空间中存储和检索。
  - 允许用户存储和处理大量非结构化数据。
  - 适合云存储和大数据应用，如Amazon S3、Google Cloud Storage和OpenStack Swift等。
- 场景：云存储服务、图床

### 二十一、基于 Redis 实现延时任务？

#### 方法一：Redis 过期事件监听

流程：

- Redis 2.0 引入了发布订阅 (pub/sub) 功能。在 pub/sub 中，引入了一个叫做 channel（频道） 的概念，有点类似于消息队列中的 topic（主题）。
- Redis 中有很多默认的 channel，这些 channel 是由 Redis 本身向它们发送消息的，其中，__keyevent@0__:expired 就是一个默认的 channel，负责监听 key 的过期事件。
- 只需要监听这个 channel，就可以拿到过期的 key 的消息，进而实现了延时任务功能。

缺点：

- 时效性差：过期事件消息是在 Redis 服务器删除 key 时发布的，而不是一个 key 过期之后就会就会直接发布。
- 消息丢失：pub/sub 模式中的消息并不支持持久化
- 多服务实例下存在消息重复消息的问题，所有订阅相关频道的消费者都能够收到该消息。

#### 方法二：Redisson 内置的延时队列

- Redisson将需要延迟执行的任务插入到SortedSet中，并给它们设置相应的过期时间作为分数。
- 使用 zrangebyscore 命令扫描SortedSet中过期的元素，然后将这些过期元素从 SortedSet 中移除，并将它们加入到**就绪消息列表**中。就绪消息列表是一个阻塞队列，有消息进入就会被监听到。

优点：

- 减少了丢消息的可能：DelayedQueue 中的消息会被持久化，即使Redis宕机了，根据持久化机制，也只可能丢失一点消息，影响不大。当然了，你也可以使用扫描数据库的方法作为补偿机制。
- 消息不存在重复消费问题：每个客户端都是从同一个目标队列中获取任务的，不存在重复消费的问题。

### 二十二、更新视频的点赞数量？

**1. 写入时延迟更新：**

- 对于每次点赞操作，先写入缓存，并且异步地批量更新到数据库中。这可以减少对数据库的直接写入操作，降低数据库的负载。

**2. 读取时合并：**

- 在读取当前的点赞总数时，需要将存储在数据库的值和缓存中的值合并。

### 二十三、内存对齐

CPU 通常以一个“字”为单位从内存中读取或写入数据，其中一个“字”的大小依赖于具体的 CPU 架构（例如，32位架构的字大小通常是 4 字节，64位架构则通常是 8 字节）当数据在内存中对齐时，数据的起始地址是其大小的整数倍，这意味着数据将恰好匹配到一个或多个内存访问操作中。

有些现代 CPU 可以处理非对齐的内存访问，但即使如此，这样的操作也往往比对齐的内存访问慢。

```
type Example struct {
    A bool    // 1 byte
    B int32   // 4 bytes
    C bool    // 1 byte
}
```

- 每个字段在内存中的起始地址应该是它类型大小的倍数。
- 整个结构体的对齐值是其所有字段中最大的对齐值。
- 为了满足对齐要求，编译器可能会在两个字段之间或结构体的末尾添加填充（padding）。

```
+---+---+---+---+---+---+---+---+
| A | P | P | P |       B       |
+---+---+---+---+---+---+---+---+
| C | P | P | P |
+---+---+---+---+

因为 B 需要 4 字节对齐，所以在 A 后面会有 3 字节的填充
为了确保整个结构体的大小是最大字段对齐值，C后面会有 3 字节的填充
```

```markdown
## 内存对齐是综合考量 字段长度 和 cpu位数 决定的

无论是 32 位还是 64 位的 CPU，`int32` 字段都会被对齐到 4 字节边界上，因为 `int32` 需要 4 字节对齐；
如果同一个结构体中还有一个 `int64` 字段
在 64 位系统上这个字段可能会被对齐到` 8 字节`边界上，
在 32 位系统上可能仍然是 4 字节边界，即使 `int64` 本身的大小是 8 字节, 因为 反正都要访问两次内存
```

### 二十四、分布式事务的难点

#### 难点：

1. 网络问题
   - **延迟**：网络通信比本地方法调用慢得多，增加了整个事务处理的时间。
   - **可用性**：网络问题或服务宕机可能导致无法访问某些资源。
2. 一致性问题
   - **数据同步**：保持分布式系统中所有副本的数据一致性非常困难。
3. 性能问题
   - **锁竞争**：分布式事务可能需要跨多个服务进行锁定资源，这可能导致高延迟和锁等待。
   - **资源消耗**：参与协调事务的每个服务都需要额外的资源来管理事务状态，记录日志等。

#### 解决方案：

- **两阶段提交（2PC）**：一种块状的原子提交协议，但可能受阻于单点故障和性能问题。
- **补偿事务（Saga模式）**：将长事务分解为一系列本地事务，每个事务都有相应的补偿操作（回滚逻辑）。
- **分布式锁**：用于同步多个服务之间对共享资源的访问。

### 二十五、在大量数据文件中查找重复（3次的）ID

```markdown
## 位图
位图（Bitmap）是一种紧凑、高效的数据表示方法，用于存储和处理大量布尔值（真/假、0/1）的信息

- 空间效率：由于每个数据元素仅用一个比特表示，位图可以大幅度节省存储空间，尤其是在数据集中大多数元素为0或1的情况下。
- 快速查询：通过对位图进行按位运算（如AND、OR、NOT、XOR），可以非常快速地执行集合操作，如成员资格测试（检查某个元素是否存在）、集合交并补等。

```

- **初始化位图**: 首先，你需要确定可能的最大ID值范围，然后创建一个足够大的位图（Bitmap）来表示这个范围内的所有ID。每个位图的位（1bit，3次的话就是2bits）对应一个ID，初始状态下所有位都设为0，表示相应ID尚未出现。
- **读取文件并更新位图**: 对于每个文件，逐行读取其中的ID，并在位图中对应的位置将0置为1。如果遇到一个ID，而位图中对应位置已经是1，说明这个ID在之前的文件中已经出现过，即为重复ID。
- **合并处理结果**: 由于需要处理三个文件，可以分别对每个文件执行上述步骤，或者一次性遍历所有文件，合并读取数据的同时更新位图。如果内存足够大，可以一次性加载所有文件的ID到内存中进行处理；如果内存有限，可能需要分批次读取文件内容。
- **查找重复ID**: 在遍历和标记位图的过程中，任何尝试置位但发现该位已经为1的ID，即为重复ID。你可以记录这些ID或者直接输出。
- **优化内存使用**: 对于非常大的ID范围，直接创建一个完整位图可能不现实。可以考虑使用分块位图、布隆过滤器（Bloom Filter）或者稀疏位图（Sparse Bitmap）等技术来减少内存占用。

```
分块位图：
按照ID的首字符(0~9)分成10个类型，分别创建对应的位图
```

### 二十六、查找算法有哪些？

- **顺序查找：**遍历列表或数组中的每个元素，直到找到目标值或遍历完所有元素。

- **二分查找**：要求数据预先排序，每次比较中间元素，根据比较结果缩小查找范围。时间复杂度为O(log n)。

- **哈希查找**：利用哈希表实现，通过哈希函数将键映射到表中的位置，理想情况下查找时间复杂度为O(1)，但在哈希冲突较多时性能会下降。

- **树形结构查找**
  - **二叉查找树**（BST）：每个节点的左子树所有节点的值小于该节点，右子树所有节点的值大于该节点。查找时间复杂度在O(log n)至O(n)之间，取决于树的平衡度。
  
  - **平衡二叉树**（如AVL树、红黑树）：在二叉查找树基础上增加了自平衡机制，确保树的高度保持在log n级别，查找时间复杂度为O(log n)。
  - **B-树和B+树**：广泛用于数据库和文件系统中，适用于磁盘等外存设备的查找，支持高效的范围查询，查找时间复杂度也为O(log n)。
  
- **图算法查找**

  - **广度优先搜索**（BFS）：从初始节点开始，一层一层地遍历图中的节点，常用于寻找最短路径问题。

  - **深度优先搜索**（DFS）：沿着一条路径尽可能深地探索图，直到到达叶子节点或无法继续前进，然后回溯。可用于拓扑排序、判断图的连通性等。

- **分块查找**：将数据分成若干块，先在索引块中查找，确定目标数据在哪一块，然后再在那块数据中进行查找，适用于大数据量的查找。

### 二十七、服务器某个端口上部署了服务，但是客户主机无法访问，怎么排查

```markdown
# 客户主机上
使用telnet命令来测试对方主机的某个端口是否能通信
   telnet 对方主机IP 80
使用nmap扫描对方主机的端口状态
   nmap -p 80 对方主机IP
```

```markdown
# 服务器主机上
查看防火墙状态：
sudo ufw status
查看防火墙规则：
sudo ufw status verbose
```

### 二十八、不同操作系统上的可执行文件为什么不通用？

- 操作系统的系统**调用接口**不同。
- 操作系统的动态链接库不同（windows是dll，linux是so，他们的api都不同）。
- 二进制文件格式不同（如 PE vs. ELF，组织代码、数据、符号表、动态链接信息等内容的方式不同）。

### 二十九、shell上输入一个命令执行的详细过程

**1. Shell 接收输入**

​	•	**命令解析**：当你在命令行中输入 ls 并按下回车，shell（例如 Bash、Zsh 等）会接收这行输入。

​	•	**命令分词**：Shell 会将输入的命令字符串分割成单词（tokens），ls 被识别为一个命令，后面的内容被识别为参数或选项（如果有的话）。

​	•	**命令查找**：Shell 查找 ls 命令的执行路径。它通常会在 PATH 环境变量指定的目录中查找可执行文件。当找到 ls 的可执行文件（例如 /bin/ls）后，它准备执行该文件。

**2. 创建子进程**

​	•	**fork()**：Shell 使用 fork() 系统调用创建一个子进程。子进程是父进程的拷贝，但它有独立的进程 ID。

​	•	**execve()**：子进程使用 execve() 系统调用来替换自己的代码段，使自己变成 ls 命令的进程。execve() 负责加载 ls 程序的可执行文件到内存中，并开始执行。

**3. 加载可执行文件**

​	•	**加载程序**：操作系统内核将 ls 可执行文件加载到子进程的地址空间中。这个过程涉及读取可执行文件的二进制数据，设置必要的内存段（如代码段、数据段、堆、栈），并将程序入口设置为 ls 的起始地址。

​	•	**动态链接**：如果 ls 依赖于共享库，动态链接器会在这个阶段加载必要的动态库（如标准 C 库 libc.so），并解析符号，使得 ls 的代码能够正确调用这些库函数。

**4. 执行 ls 命令**

​	•	**进程执行**：ls 程序开始执行，首先执行其 main 函数。ls 会处理命令行参数（如果有），确定显示哪些文件或目录，是否显示详细信息，是否递归显示子目录等。

​	•	**系统调用**：ls 使用系统调用（如 open, read, getdents, stat, close 等）与操作系统交互。具体来说：

​	•	getdents 或 readdir 系统调用用于读取目录内容（获取当前目录下的文件和目录列表）。

​	•	stat 系统调用用于获取文件的详细信息（如文件大小、权限、最后修改时间等）。

**5. 输出结果**

​	•	**输出处理**：ls 收集到所有文件和目录的信息后，将它们按照指定的格式（如按行排列或按列排列）进行排序和格式化。

​	•	**写入标准输出**：ls 使用 write 系统调用将结果写入标准输出（通常是终端）。

​	•	**终端显示**：终端接收这些数据并显示在屏幕上，用户可以看到目录内容的列表。

**6. 进程结束**

​	•	**进程终止**：当 ls 命令完成所有操作后，它会调用 exit 函数，该函数调用 exit 系统调用，通知操作系统进程已经完成。

​	•	**资源回收**：操作系统回收 ls 进程使用的所有资源（如内存、文件描述符等），并将其状态报告给父进程（即原始的 shell 进程）。

​	•	**Shell 恢复控制**：Shell 进程通过 wait 系列系统调用等待 ls 进程的结束。ls 进程结束后，Shell 恢复控制权，准备处理下一个命令。

### 三十、Redis延时消息

方法：ZSET

- 使用消息的预定执行时间作为分数，将消息存储在 Sorted Set 中。
- 一个后台任务或者定时任务（例如每秒一次），通过 ZRANGEBYSCORE 命令查询并获取分数小于等于当前时间戳的消息，即已经到期的消息（后续处理）。

问题：

- **精度问题**：使用 Sorted Set 实现延时消息时，定时任务的执行频率会影响延时的精度。如果任务执行间隔较大，可能会导致消息延迟处理。通常需要根据业务需求调整定时任务的扫描频率。
- **可靠性**：如果 Redis 实例重启或者崩溃，延时消息可能会丢失。为了增强可靠性，可以采用持久化存储和主从备份等策略。
- **性能**：在高并发场景下，频繁地插入和删除消息可能会影响 Redis 的性能。可以通过批量操作和异步处理等方式优化性能。

### 三十一、优先级调度中如何解决低优先级的饥饿问题？

**优先级老化：**随着时间的推移，系统逐渐提高低优先级进程的优先级。这种机制确保了一个进程等待的时间越长，它的优先级就会越高，直到最终获得 CPU 资源。

**保证执行比例：**操作系统可以为所有优先级的进程设置一个最低的执行比例，确保即使是最低优先级的进程，在一定时间内也能获得执行机会。例如，规定低优先级进程在每秒至少获得一定数量的 CPU 时间片。

三十二、执行print("hello world")的具体过程

1. ​	Python 解释器解析并执行 print 语句。
2. ​	print 函数调用 C 标准库 fwrite 或类似函数，将字符串传递给标准输出。
3. ​	标准库通过系统调用 write 将数据交给操作系统内核。
4. ​	操作系统将数据放入输出缓冲区，并交给设备驱动程序。
5. ​	驱动程序将数据传递给显示设备，最终字符显示在屏幕上。

```
在 Unix中，标准输出（stdout）和标准输入（stdin）。虽然它们被称为“文件”，但它们并不是普通的文件，而是文件描述符与某种输入输出设备或资源（如终端、网络、文件等）的连接。
```

每个进程在启动时会自动获得三个打开的文件描述符：

- 0（stdin）：标准输入
- 1（stdout）：标准输出
- 2（stderr）：标准错误

在默认情况下，stdout 被指向了显示设备（通常是用户终端，控制台）；stdin默认关联到键盘输入设备；stderr默认也关联到屏幕或终端。

- 操作系统和编程语言的标准库为了提高效率，通常会对输出的数据进行**缓冲**，print() 输出的字符串首先被写入**标准库缓冲区**，这是位于内存中的一块区域。（缓冲区满了，或者遇到了换行符 \n 时，缓冲区的内容会被自动刷新）
- 当标准库的缓冲区被刷新时，数据通过系统调用（如 write()）被写入操作系统内核管理的文件描述符 stdout。此时，数据仍然在内存中（内核缓冲区）
- 操作系统将内核缓冲区中的数据发送到终端的字符缓冲区，屏幕的驱动程序负责将数据转换为光信号。
