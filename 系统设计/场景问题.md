## 场景问题

### 一、负载均衡

#### 负载均衡的算法有哪些

 **轮询**：负载均衡系统接收到请求后，**按照顺序轮流分配给服务器**。这种方式非常简单，只管按顺序分配，至于服务器当前负载情况、硬件能力等都不关心，只要服务器还能工作，就可以分配，除非服务器挂了。
 **加权轮询**：是轮询方式的一种改进，轮询方式是无差别分配，但实际服务器的处理能力是有差异的，所以需要区别对待。**为服务器设置权值，权值高的就多分配点**。
 **负载最低优先**：将任务分配给当前负载最低的服务器。例如 LVS 可以根据“连接数”判断服务器状态，NGINX 可以根据“HTTP请求数”来判断。这种方式比轮询高级很多，可以感知服务器的状态了，但其复杂度也大大提高了，要收集统计服务器的负载信息。
 **性能最优**：优先将任务分配给**处理速度最快的服务器**，来达到最快响应客户端的目的。此方式也是感知服务器的状态，标准是**响应时间**。需要收集分析服务器的响应时间，这个工作本身消耗也不小，所以采用**采样**的方式，不统计所有任务的响应时间，统计一个周期（例如 10秒/1分钟/5分钟）内的状态。优缺点与负载最低优先相同。
 **Hash**：**对请求中的关键信息（如IP）进行hash计算**，hash 值相同的请求分配到同一台服务器，例如业务中希望同一用户的请求都由同一台服务器来处理。

#### 一致性哈希算法

**普通的服务器哈希算法：**如果你有 *n* 个缓存服务器，*服务器索引 = 哈希(键) % N*，其中 *N* 是服务器池的大小。当新的服务器被添加，或者现有的服务器被移除时，大多数键都被重新分配了，这意味着，大多数缓存客户端将连接到错误的服务器来获取数据，导致了一场缓存未命中的风暴。

**一致性哈希：**一致性哈希是一种特殊的哈希，使得当哈希表大小改变且使用一致性哈希时，平均只有 k/n 个键需要被重新映射，其中 k 是键的数量，n 是槽位的数量。相比之下，在大多数传统哈希表中，数组槽位数量的变化导致几乎所有的键都需要被重新映射。

##### 哈希环

- 使用均匀分布的哈希函数将服务器和键映射到环上。
- 要找出键映射到哪个服务器，从键位置开始顺时针方向找到环上的第一个服务器。

![image-20230520221817073](https://gitee.com/xu_zuyun/picgo/raw/master/img/1f9d58cc2f204c4fb073a205c517d621.png)

使用上述逻辑，添加新服务器只需要重新分配一部分键。

问题：服务器可能会被添加或移除，环上的键分布可能非均匀。

##### 虚拟节点

虚拟节点是指实际节点，每个服务器在环上都由多个虚拟节点表示。随着虚拟节点数量的增加，键的分布变得更加均衡。这是因为随着虚拟节点数量的增加，标准差变得更小，导致数据分布均衡。然而，我们需要更多的空间来存储虚拟节点的数据。这是一个权衡，我们可以调整虚拟节点的数量以适应我们的系统需求。

![image-20230520221923607](https://gitee.com/xu_zuyun/picgo/raw/master/img/c618b83889b247888100b390fc328286.png)

### 二、手机扫二维码登陆的原理

![字节二面：扫码登录的原理](https://gitee.com/xu_zuyun/picgo/raw/master/img/v2-23efbeaf98a5e66775635b01e7801b4c_1440w.png)

##### 为什么用临时token？

临时token与token一样，它也是一种身份凭证，不同的地方在于它只能用一次，用过就失效。同时防止被坏人拦截token去冒充登录（token和设备是绑定的，故攻击者获取了手机长期token也无法在新设备上使用）

##### 为什么使用多次token？

以此确保扫码，登录两步操作是同一部手机端发出的。

### 三、分布式系统ID生成

**唯一性：**由于分布式系统包含多个节点，需要确保在不同的服务器、地理位置或时间点上创建的ID是全局唯一的，以便能够无歧义地识别和引用特定的数据或对象。

**去中心化：**为了高效率和可扩展性，分布式系统往往要求去中心化操作，这意味着每个节点应该能够独立生成ID，而不依赖于中央机构或服务。这减少了网络开销、避免了单点故障，并提升了系统整体的可用性。

**有序性：**某些应用场景可能需要ID具备一定的有序性，例如，一个增长的ID可以帮助保持数据存储在数据库中的顺序，从而优化检索速度。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/format,png-20240111145209266.png)

雪花算法的原理就是生成一个的 64 位比特位的 long 类型的唯一 id。

- 最高 1 位固定值 0，因为生成的 id 是正整数，如果是 1 就是负数了。
- 接下来 41 位存储毫秒级时间戳，2^41/(1000*60*60*24*365)=69，大概可以使用 69 年。
- 再接下 10 位存储机器码，包括 5 位 datacenterId 和 5 位 workerId。最多可以部署 2^10=1024 台机器。
- 最后 12 位存储序列号。同一毫秒时间戳时，通过这个递增的序列号来区分。即对于同一台机器而言，同一毫秒时间戳下，可以生成 2^12=4096 个不重复 id。

注意：依赖服务器时间，服务器时钟回拨时可能会生成重复 id。算法中可通过记录最后一个生成 id 时的时间戳来解决，每次生成 id 之前比较当前服务器时钟是否被回拨，避免生成重复 id。

##### 为什么要用雪花ID？

- **数据库自增 ID** 只适用于单机环境，但如果是分布式环境，是将数据库进行分库、分表或数据库分片等操作时，那么数据库自增 ID 就有问题了。

- **UUID** 内容很长，但没有业务含义，就是一堆看不懂的“字母”。UUID 是字符串类型，而字符串类型在数据库的查询中效率很低。

### 四、布隆过滤器

在十亿级别用户中检查用户名是否存在？            

**布隆过滤器**（`Bloom Filter`）是一**种数据结构**，用于快速检查一个元素是否存在于一个大型数据集中，通常用于在某些情况下快速过滤掉不可能存在的元素，以减少后续更昂贵的查询操作。布隆过滤器的主要优点是它可以提供快速的查找和插入操作，并且在内存占用方面非常高效。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/c75956be47c24514ba6a150af139e00d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

布隆过滤器的核心思想是使用一个位数组（`bit array`）和一组哈希函数。

- **位数组（Bit Array）** ：布隆过滤器使用一个包含大量位的数组，通常初始化为全0。每个位可以存储两个值，通常是0或1。这些位被用来表示元素的存在或可能的存在。
- **哈希函数（Hash Functions）** ：布隆过滤器使用多个哈希函数，每个哈希函数可以将输入元素映射到位数组的一个或多个位置。这些哈希函数必须是独立且具有均匀分布特性。

那么具体是怎么做的呢？

- **添加元素**：如上图所示，当将字符串“`xuyang`”，“`alvin`”插入布隆过滤器时，通过多个哈希函数将元素映射到位数组的多个位置，然后将这些位置的位设置为1。
- **查询元素**：当要检查一个元素是否存在于布隆过滤器中时，通过相同的哈希函数将元素映射到位数组的相应位置，然后检查这些位置的位是否都为1。如果有任何一个位为0，那么可以确定元素不存在于数据集中。但如果所有位都是1，元素可能存在于数据集中，但也可能是误判。

```java
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
import redis.clients.jedis.JedisPoolConfig;

public class BloomFilterExample {
    public static void main(String[] args) {
        JedisPoolConfig poolConfig = new JedisPoolConfig();
        JedisPool jedisPool = new JedisPool(poolConfig, "localhost", 6379);

        try (Jedis jedis = jedisPool.getResource()) {
            // 创建一个名为 "usernameFilter" 的布隆过滤器，需要指定预计的元素数量和期望的误差率
            jedis.bfCreate("usernameFilter", 10000000, 0.01);
            
            // 将用户名添加到布隆过滤器
            jedis.bfAdd("usernameFilter", "alvin");
            
            // 检查用户名是否已经存在
            boolean exists = jedis.bfExists("usernameFilter", "alvin");
            System.out.println("Username exists: " + exists);
        }
    }
}
```

**优点：**

- **节约内存空间**，相比使用哈希表等数据结构，布隆过滤器通常需要更少的内存空间，因为它不存储实际元素，而只存储元素的哈希值。如果以 0.001 误差`概`率存储 `10` 亿条记录，只需要 `1.67 GB` 内存，对比原来的`20G`，大大的减少了。
- **高效的查找**， 布隆过滤器可以在常数时间内`（O(1)）`快速查找一个元素是否存在于集合中，无需遍历整个集合。

**缺点：**

- **误判率存在**：布隆过滤器在判断元素是否存在时，有一定的误判率。这意味着在某些情况下，它可能会错误地报告元素存在，但不会错误地报告元素不存在。
- **不能删除元素**：布隆过滤器通常不支持从集合中删除元素，因为删除一个元素会影响其他元素的哈希值，增加了误判率。

##### 布隆过滤器为什么要求多个哈希值？

使用多个哈希函数的原因是增加随机性，这样每个元素都会影响位数组中多个位置。如果只使用一个哈希函数，所有元素影响的位置就少了，从而更容易发生冲突，导致误报率上升。

##### 布隆过滤器你怎么设置的长度？

布隆过滤器的长度（位数组的大小），通常根据预期要存储的元素数量（n）和可接受的误判率（p）来计算，以及哈希函数的数量（k）计算得到

### 五、谈谈SSO单点登录的设计实现

单点登陆：学校的网站，有很多个系统，迎新系统，教务系统，网课系统，只需要登录一次就能在各个系统中被认定为登录状态。

#### Cookie共享传播状态

认证中心和其他系统是在一个域名下的，认证中心为父域名(jwxt.com)，其他系统是子域名(yx.jwxt.com)，或者是同一IP不同端口的情况，我们的服务端通过cookie去判断是否登录。

在认证中心登录成功的时候设置Cookie，**domin**要设置为父域名(.jwxt.com)，设置**SameSite**，此后子域名的系统也有了Cookie。

#### Session共享

使用Session共享技术，将Session信息存储在一个外部存储中，比如Redis、MongoDB等，从而实现多个应用程序之间的Session共享。使用一些现成的框架来实现Session共享，比如Spring Session、Apache Shiro。

- 数据库共享：将session存储在数据库中，不同的应用服务器通过访问同一数据库来实现session共享。
- Cookie共享：将session ID存储在cookie中，不同的应用服务器通过访问同一域名下的cookie来实现session共享。
- 缓存共享：将session存储在缓存中，不同的应用服务器通过访问同一缓存来实现session共享。常用的缓存系统有Redis、Memcached等。

#### Oauth2

基于OAuth2.0的单点登录：OAuth2.0是一种授权框架，可以用于实现单点登录。用户在第一次登录时，服务器会将用户的授权信息存储在OAuth2.0服务器中。当用户访问其他应用程序时，这些应用程序会向OAuth2.0服务器请求授权信息，如果授权信息有效则认为用户已经登录。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/v2-83662b2b5f33ebbd63124cc590b91673_1440w.webp)

### 五、实现文件上传

以nginx为例：

- 其默认允许1MB以内的文件
- 超过1MB的文件，需要设置`client_max_body_size`放开体积限制，但服务器的存储和网络带宽压力都会非常大

流程

- 将大文件分割成多个文件块
- 逐个上传文件块
- 服务端将文件块顺序合并成完整文件

#### Java上传

```java
package com.example.demo.controller;

import cn.dev33.satoken.annotation.SaCheckLogin;
import com.example.demo.common.Result;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.multipart.MultipartFile;

import javax.servlet.ServletOutputStream;
import javax.servlet.http.HttpServletResponse;
import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.util.UUID;

@Slf4j
@RestController
@RequestMapping("/common")
public class CommonController {

    @Value("${takeOutFile.fileLocaltion}")
    private String basePath ;

    @PostMapping("/upload")
    public Result<String> upload(MultipartFile file){
        //这里的file只是一个临时的文件存储，临时存储到某一个位置，然后待接收完毕后再转存到目标位置上，然后再把这个临时文件删除
        //截取文件后缀
        String suffix = file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf('.'));
        //生成UUID
        String randomUUID = UUID.randomUUID().toString();
        //拼接文件最后名称，结果为文件本体名字+UUID+后缀
        String fileName = file.getOriginalFilename() + randomUUID + suffix;

        //保证存储的位置有这个文件夹
        File dir = new File(basePath);
        if (!dir.exists()) {
            //目标存储位置不存在，就创建一个文件夹
            dir.mkdirs();
        }

        try {
            //转存文件到指定位置+文件的名称全拼
            file.transferTo(new File(basePath+fileName));
        } catch (IOException e) {
            e.printStackTrace();
        }
        //把文件的名字上传回去，方便后续回显读取路径
        return Result.success(fileName);
    }

    /**
     * 文件回显接口
     * @param httpServletResponse 响应对象
     * @param name 上传的文件名称
     * @throws IOException IO异常
     */
    @GetMapping("/download")
    public void fileDownload(HttpServletResponse httpServletResponse, String name) throws IOException {
        //把刚刚存的文件读取到内存中，准备回显
        FileInputStream fileInputStream = new FileInputStream(new File(basePath+name));
        log.info("文件存储的位置为："+basePath+name);
        //把读取到内存中的图片用输出流写入Servlet响应对象里
        ServletOutputStream servletOutputStream = httpServletResponse.getOutputStream();

        //可选项，选择响应类型
        httpServletResponse.setContentType("image/jpeg");

        //用byte数组写入，注意是小写b，不是大写，大写就是包装类了
        byte[] fileArray = new byte[1024];
        int length=0;
        try {
            //只要没读到数组的尾部就一直读下去，这部分是IO的内容
            while ((length=fileInputStream.read(fileArray))!=-1) {
                //写入响应流，从0开始，写入到数组末尾长度
                servletOutputStream.write(fileArray, 0, length);
                //把流里的东西挤出来
                servletOutputStream.flush();
            }
        } catch (IOException e) {
            e.printStackTrace();
        }finally {
            //关闭流
            fileInputStream.close();
            servletOutputStream.close();
        }
        return;
    }
}
```

### 六、防止非法盗链

通过检查HTTP头部中的Referer字段，判断请求来源是否合法。只允许来自特定域名或IP地址的请求才能访问资源。这种方法较容易实施，不过存在一定的伪造风险。

referer字段：表示页面从哪里跳转而来。例如：A跳转到了B，在B中查看请求头时就可以看到Referer字段的值为A地址。

- 1、网页中的超链接。
- 2、用户发送表单。
- 3、网页加载静态资源；例如：图片、脚本、样式等

```java
public class RefererFilter implements Filter {

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {
		System.out.println("初始化方法...");
    }
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {
 	    System.out.println("拦截请求...");
 	    
        HttpServletRequest req = (HttpServletRequest) request;
        HttpServletResponse res = (HttpServletResponse) response;
        //每次请求来源 （）
        String referer = req.getHeader("referer");
        //获取请求地址，返回当前页面所在的服务器的名字访问路径：http://127.0.0.1:8080/demo/ -> 返回：127.0.0.1
        String serverName = req.getServerName();
        
        System.out.println("referer:" + referer + "---serverName" + serverName);
        
        if (referer == null || !referer.contains(serverName)) {
            req.getRequestDispatcher("/static/images/error.png").forward(req, res);
            return;
        }
        //放行
        chain.doFilter(req, res);
    }
    @Override
    public void destroy() {
		System.out.println("销毁请求...");
    }
}
```

### 七、有哪些常用限流算法？

#### Leaky Bucket 漏桶

漏桶可理解为是一个限定容量的请求队列。想象有一个桶，有水（指请求或数据）从上面流进来，水从桶下面的一个孔流出来。水流进桶的速度可以是随机的，但是水流出桶的速度是恒定的。 当水流进桶的速度较慢，桶不会被填满，请求就可以被处理。 当水流进桶的速度过快时，桶会逐渐被填满，当水超过桶的容量就会溢出，即被丢弃。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/202309090040484.png)

#### Token Bucket 令牌桶

在令牌桶算法中，系统会以一个固定的速率向桶中添加令牌。当有请求（或数据包）到来时，会从桶中删除一定数量的令牌。如果桶中有足够的令牌，请求就可以立即处理； 如果桶中没有足够的令牌，请求就会被阻塞或丢弃，具体行为取决于具体的实现。 桶有容量限制，如果添加令牌时桶已满，新的令牌就会被丢弃。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/20220209161224.png)

```markdown
## 漏桶 (Leaky Bucket):
数据以固定的速率离开漏桶。
即使网络中没有数据传输，包也会以恒定的速率进行排队。
这导致数据输出具有很高的确定性。

## 令牌桶 (Token Bucket):
数据可以以任何速率进入桶内，只要桶内有令牌，数据就能以任意速率发送，直到达到网络最大速率。
允许某种程度的突发性，因为如果桶中有足够的令牌，数据可以快速发送。
相对来说，输出速率更加灵活。
```

#### Fixed Window 固定窗口

在一个固定的时间窗口内，只允许一定数量的请求。如果在这个时间窗口内的请求已经达到了限制，那么新的请求就会被拒绝，过了当前时间窗口后，会进入下一个时间窗口，并重置窗口内的请求数量，重新计算。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/20220209144040.png)

#### Sliding Window 滑动窗口

在固定窗口限流算法中，如果大量请求在一个时间窗口的边界附近到达，可能会造成瞬时的流量突增。 滑动窗口随着时间的推移，动态统计请求量，避免了在窗口边界附近的流量突增。

### 八、服务器集群中的session共享方案有哪些？

#### 1、session复制同步方案

解决方式:每个节点都复制其他节点的session

```markdown
## 优点：
web-server(tomcat)不需要额外开发，只需搭建tomcat集群即可,修改配置文件
## 缺点：
数据传输占用带宽,内存限制
```

#### 2、cookie客户端存储

解决方式:session存储在客户端的cookie中
```markdown
## 优点:
服务器不需存储session，用户保存自己的 session信息到cookie中。节省服务端资源
## 缺点:
1.每次http请求，携带用户在cookie中的完整信息，浪费网络带宽
2.session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患
3.session数据放在cookie中，cookie有长度限制4K，不能保存大量信息
```

#### 3、nginx ip_hash一致性

解决方式:固定的用户固定的请求一台服务器
```markdown
## 优点：
只需要改nginx配置，不需要修改应用代码
负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的
可以支持web-server水平扩展（session同步法是不行的，受内存限制）
## 缺点:
服务器重启可能导致部分session丢失，影响业务，如部分用户需要重新登录
如果服务器水平扩展，rehash后session重新分布，会有用户路由不到正确的session
但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用
```

#### 4、统一存储

解决方式:后端统一存储session
```markdown
## 优点：
没有安全隐患；
可以水平扩展，数据库/缓存 水平切分即可；
服务器重启或者扩容都不会有session丢失。
## 缺点:
增加了一次网络调用；
如将所有的getSession方法替换为从Redis查数据的方式。
缺点可以用SpringSession完美解决。
```

### 九、零拷贝技术

Netty 用到了零拷贝来大幅提升网络吞吐量

正常流程：4次拷贝，4次用户态和内核态之间的切换

![非DMA非零拷贝 (1).png](https://gitee.com/xu_zuyun/picgo/raw/master/img/6fe8074c922b43a3b190ea000087da67~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

1. 应用进程向系统申请读磁盘的数据，这时候程序从用户态切换成内核态。
2. 系统也就是 linux 系统得知要读数据会通知 DMA 模块要读数据，这时 DMA 从磁盘拉取数据写到系统内存中。
3. 系统收到 DMA 拷贝的数据后把数据拷贝到应用内存中，同时把程序从内核态变为用户态。
4. 应用内存拿到从应用内存拿到数据后，会把数据拷贝到系统的 Socket 缓存，然后程序从用户态切换为内核态。
5. 系统再次调用 DMA 模块，DMA 模块把 Socket 缓存的数据拷贝到网卡，从而完成数据的发送，最后程序从内核态切换为用户态。

#### MMAP + write

```c
buf = mmap(file,length) 
write(socket,buf,length)
  // 所谓的 MMAP， 其实就是系统内存某段空间和用户内存某段空间保持一致，也就是说应用程序能通过访问用户内存访问系统内存
```

- 应用进程通过接口调用系统接口 MMAP，并且进程从用户态切换为内核态。
- 系统收到 MMAP 的调用后用 DMA 把数据从磁盘拷贝到系统内存，这时是第1次数据拷贝。由于这段数据在系统内存和应用内存是共享的，数据自然就到了应用内存中，这时程序从内核态切换为用户态。
- 程序从应用内存得到数据后，会调用 write 系统接口，这时第2次拷贝开始，具体是把数据拷贝到 Socket 缓存，而且用户态切换为内核态。
- 系统通过 DMA 把数据从 Socket 缓存拷贝到网卡。
- 最后，进程从内核态切换为用户态。

这样做到收益是`减少了一次拷贝`，`但是用户态和内核态仍然是4次切换`。

#### sendfile

![零拷贝之sendfile.png](https://gitee.com/xu_zuyun/picgo/raw/master/img/a08835b5b0cd41d7aaca88d4089f3c08~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

1. 应用进程调用系统接口 sendfile，进程从用户态切换完内核态。
2. 系统接收到 sendfile 指令后，通过 DMA 从磁盘把数据拷贝到系统内存。
3. 数据到了系统内存后，CPU 会把数据从系统内存拷贝到 socket 缓存中。
4. 通过 DMA 拷贝到网卡中。
5. 最后，进程从内核态切换为用户态。

#### 零拷贝

1. 应用进程调用系统接口 sendfile，进程从用户态切换完内核态。
2. 系统接收到 sendfile 指令后，通过 DMA 从磁盘把数据拷贝到系统内存。
3. 数据到了系统内存后，CPU 会把文件描述符和数据长度返回到 socket 缓存中（注意这里没有拷贝数据）。
4. 通过 SG-DMA 把数据从系统内存拷贝到网卡中。
5. 最后，进程从内核态切换为用户态。

![真正的零拷贝.png](https://gitee.com/xu_zuyun/picgo/raw/master/img/c3ace07d37cb4157bc27435369549eeb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

`零拷贝在用户态和内核态之间的切换是2次，拷贝是2次`，在内存之间没有拷贝，大大减少了切换次数和拷贝次数,而且全程没有 CPU 参与数据的拷贝。

```markdown
## SG-DMA
在通常情况下，DMA 操作是在一个连续的内存块上执行的。然而，在实际应用中，所需的数据可能是分散的，即分布在物理内存的多个不同区域。Scatter-Gather DMA 就是为了解决这个问题而设计的：

- 分散（Scatter）：指的是从内存的多个不连续位置读取数据块，并"分散"到连续的硬件缓冲区中，或者相反，将数据从硬件的连续缓冲区写入到内存的分散区域。

- 聚集（Gather）：则是指将来自多个源的数据“聚集”起来，组合成一个大的数据块，以便连续地通过 DMA 传输。

为实现这一过程，操作系统通常会维护一个描述符表或链表，列出所有分散内存区块的地址和大小。DMA 控制器使用这个表来了解每个数据块的位置，并按正确的顺序将它们聚集起来进行传输。

Scatter-Gather DMA 在需要高效处理大量分散数据的场景下非常有用，比如在网络通信、文件系统管理和音视频数据流处理中。它消除了额外的数据拷贝步骤，因为它允许直接在分散的内存区块上操作，从而减少了延迟，提高了吞吐量，并减轻了 CPU 负担。
```

### 十，token刷新技术

### Access Token

1. **有限授权**: Access tokens 代表用户给予应用程序的有限权限。这意味着即使第三方获得了 token，它也只能访问被授权的资源和操作。
2. **短期有效性**: Access tokens 通常有很短的有效期（比如一个小时）。这意味着即使 token 被泄露，攻击者也只能在有限的时间内使用它。
3. **减少持续性风险**: 由于 access token 有短期的有效性，因此它们减少了因长期有效的凭证被盗而带来的风险。

### Refresh Token

1. **增强的安全性措施**: Refresh tokens 通常只能与颁发它们的认证服务器交互，并且可能需要额外的验证。这意味着即使 refresh token 被泄露，恶意用户也难以利用它。
2. **更长的生命周期**: 由于 refresh tokens 不用来直接访问资源，它们可以拥有相对更长的生命周期，减少了用户需要频繁登录的次数，改善了用户体验。

access token 是客户端访问资源服务器的令牌。拥有这个令牌代表着得到用户的授权。然而，这个授权应该是临时的，有一定有效期。这是因为，access token 在使用的过程中可能会泄露。给 access token 限定一个较短的有效期可以降低因 access token 泄露而带来的风险。

　　然而引入了有效期之后，客户端使用起来就不那么方便了。每当 access token 过期，客户端就必须重新向用户索要授权。这样用户可能每隔几天，甚至每天都需要进行授权操作。这是一件非常影响用户体验的事情。希望有一种方法，可以避免这种情况。

　　于是 Oauth2.0 引入了 refresh token 机制。refresh token 的作用是用来刷新 access token。鉴权服务器提供一个刷新接口，例如：http://xxx.xxx.com/refresh?refreshtoken=&client_id=

　　传入 refresh token 和 client_id，鉴权服务器验证通过后，返回一个新的 access token。为了安全，Oauth2.0 引入了两个措施：

　　1，Oauth2.0 要求，refresh token 一定是保存在客户端的服务器上的，而绝不能存放在狭义的客户端（例如移动 app、PC端软件） 上。调用 refresh 接口的时候，一定是从服务器到服务器的访问；

　　2，Oauth2.0 引入了 client_secret 机制。即每一个 client_id 都对应一个 client_secret。这个 client_secret 会在客户端申请 client_id 时，随 client_id 一起分配给客户端。客户端必须把 client_secret 妥善保管在服务器上，决不能泄露。刷新 access token 时，需要验证这个 client_secret。

　　于是，实际上的刷新接口应该是类似这样的：http://xxx.xxx.com/refresh?refreshtoken=&client_id=&client_secret=refresh token 的有效期非常长，会在用户授权时，随 access token 一起重定向到回调 url，传递给客户端。

```markdown
## 实现原理：

在access_token里加入refresh_token标识，给access_token设置短时间的期限（例如一天），给refresh_token设置长时间的期限（例如七天）。当活动用户（拥有access_token）发起request时，在权限验证里，对于requeset的header包含的access_token、refresh_token分别进行验证：

1、access_token没过期，即通过权限验证；

2、access_token过期,refresh_token没过期，则返回权限验证失败，并在返回的response的header中加入标识状态的key，在request方法的catch中通过webException来获取标识的key，获取新的token（包含新的access_token和refresh_token），再次发起请求，并返回给客户端请求结果以及新的token，再在客户端更新公共静态token模型；

3、access_token过期,refresh_token过期即权限验证失败。
```

### 十一，百亿数据中找中位数

1. 桶/计数排序思想

   根据数据的特征，比如数据落在某个固定范围内，可以使用桶排序或计数排序的思想。通过统计每个桶内元素的数量，我们可以确定中位数所在的桶，然后在该桶内使用更精确的方法计算中位数。

2. 外部排序

   如果数据无法一次性装入内存，则可以使用外部排序。这个过程包括将数据分割成多个块，每个块单独排序并存储在外部存储器（如硬盘）上，再将这些有序的块合并来找出整体的中位数。

   ```markdown
   1. 分割数据
   将原始数据集分割成多个小块，称为“runs”或“chunks”。每个小块的大小应当适合放入内存中进行排序。
   
   2. 排序小块
   读取每个小块至内存，使用内部排序算法（如快速排序、堆排序等）对其进行排序。
   
   3. 存储排序后的小块
   将排序后的小块写回到外部存储（硬盘等）上。这样，硬盘上就有了多个有序的数据块。
   
   4. 归并排序
   使用N路归并排序算法，将所有有序的小块合并成一个完整有序的数据集。这个步骤通常涉及以下操作：
   
   创建一个优先队列（最小堆），初始化时将每个有序块的第一个元素加入。
   不断从优先队列（堆）中取出最小元素，并将该元素所在块的下一个元素加入队列。
   将取出的最小元素写入到最终的输出文件中。
   重复以上过程直到所有块中的元素都被处理。
   5. 输出最终结果
   最终，所有数据块中的元素都按顺序写入到最终输出文件中，完成总体的排序任务。
   
   外部排序的效率很大程度上取决于磁盘IO的速度以及归并阶段处理有序块的效率。在现代操作系统中，通常会使用缓冲区来减少磁盘IO次数，提高外部排序的速度。
   ```

3. MapReduce估算中位数

   - 将数字按范围（数位大小）分到不同的桶中

   - 每个分位桶排序计算得到一个局部中位数

   - 以中间两个桶的局部中位数为基础来估算全局中位数

### 十二，海量数据，求TopK问题

海量日志数据，提取出某日访问百度次数最多的那个IP，如果想一次性把所有IP数据装进内存处理，则内存容量明显不够，故针对数据太大，内存受限的情况，可以把大文件转化成（取模映射）小文件，从而大而化小，逐个处理。换言之，先映射，而后统计，最后排序。

具体分为以下3个步骤

> - 1.分而治之/hash映射
>   - 首先把这一天访问百度日志的所有IP提取出来，然后逐个写入到一个大文件中，接着采用映射的方法，比如%1000，把整个大文件映射为1000个小文件。
> - 2.hash_map统计
>   - 当大文件转化成了小文件，那么我们便可以采用hash_map(ip, value)来分别对1000个小文件中的IP进行频率统计，再找出每个小文件中出现频率最大的IP。
> - 3.堆/快速排序
>   - 统计出1000个频率最大的IP后，依据各自频率的大小进行排序(可采取堆排序)，找出那个频率最大的IP，即为所求。
>
> 注：Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中去的情况，即这里采用的是%1000算法，那么同一个IP在hash后，只可能落在同一个文件中，不可能被分散的。

同样的，有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

解法：

> - 1.分而治之/hash映射
>   - 顺序读取文件，对于每个词x，取hash(x)%5000，然后把该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。当然，如果其中有的小文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。
> - 2.hash_map统计
>   - 对每个小文件，采用trie树/hash_map等统计每个文件中出现的词以及相应的频率。
> - 3.堆/归并排序
>   - 取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。

参考：https://www.cnblogs.com/xingyunblog/articles/9078808.html

### 十三、如何设计一个比较两篇文章相似度的算法？

局部敏感哈希（Locality-Sensitive Hashing，LSH）是一种用于快速相似性搜索的算法技术。该技术主要用于高维空间中的数据，其目标是为相似的对象生成相同或相近的哈希值，而对于不相似的对象则生成不同的哈希值。通过这种方式，LSH能够在大规模数据集中高效地执行近邻搜索任务。

```
特点：
局部敏感性：如果两个数据点相似，那么它们被哈希到相同桶中的概率会很高。
可调性：LSH家族通常有参数可以调整，以控制相似度与哈希碰撞概率之间的平衡。
```

simhash作为locality sensitive hash（局部敏感哈希）的一种：

- 其主要思想是降维，将高维的特征向量映射成低维的特征向量，通过两个向量的Hamming Distance来确定文章是否重复或者高度近似。

  其中，Hamming  Distance，又称汉明距离，在信息论中，两个等长字符串之间的汉明距离是两个字符串对应位置的不同字符的个数。如此，通过比较多个文档的simHash值的海明距离，可以获取它们的相似度。

simhash算法分为5个步骤：分词、hash、加权、合并、降维，具体过程如下所述：

- 分词
  - 给定一段语句，进行分词，得到有效的特征向量，然后为每一个特征向量设置1-5等5个级别的权重（如果是给定一个文本，那么特征向量可以是文本中的词，其权重可以是这个词出现的次数）。例如给定一段语句：“CSDN博客结构之法算法之道的作者July”，分词后为：“CSDN 博客 结构 之 法 算法 之 道 的 作者 July”，然后为每个特征向量赋予权值：CSDN(4) 博客(5) 结构(3) 之(1) 法(2) 算法(3) 之(1) 道(2) 的(1) 作者(5) July(5)，其中括号里的数字代表这个单词在整条语句中的重要程度，数字越大代表越重要。
- hash
  - 通过hash函数计算各个特征向量的hash值，hash值为二进制数01组成的n-bit签名。比如“CSDN”的hash值Hash(CSDN)为100101，“博客”的hash值Hash(博客)为“101011”。就这样，字符串就变成了一系列数字。
- 加权
  - 在hash值的基础上，给所有特征向量进行加权，即W = Hash *  weight，且遇到1则hash值和权值正相乘，遇到0则hash值和权值负相乘。例如给“CSDN”的hash值“100101”加权得到：W(CSDN) = 100101_4 = 4 -4 -4 4 -4 4，给“博客”的hash值“101011”加权得到：W(博客)=101011_5 = 5  -5 5 -5 5 5，其余特征向量类似此般操作。
- 合并
  - 将上述各个特征向量的加权结果累加，变成只有一个序列串。拿前两个特征向量举例，例如“CSDN”的“4 -4 -4 4 -4  4”和“博客”的“5 -5 5 -5 5 5”进行累加，得到“4+5 -4+-5 -4+5 4+-5 -4+5 4+5”，得到“9 -9 1  -1 1”。
- 降维
  - 对于n-bit签名的累加结果，如果大于0则置1，否则置0，从而得到该语句的simhash值，最后我们便可以根据不同语句simhash的海明距离来判断它们的相似度。例如把上面计算出来的“9 -9 1 -1 1 9”降维（某位大于0记为1，小于0记为0），得到的01串为：“1 0 1 0 1 1”，从而形成它们的simhash签名。

### 十四、日常有哪些攻击手段以及相应的防护措施？

##### 1. 分布式拒绝服务攻击（DDoS，Distributed Denial of Service）

- **描述**：通过大量恶意流量使服务器或网络资源不可用。

  ```
  Volumetric Attacks（容量型攻击）：
  这类攻击试图耗尽目标网络的带宽，例如通过UDP洪泛（UDP flood）或ICMP洪泛（ICMP flood）。
  
  Protocol Attacks（协议攻击）：
  这些攻击目标是网络层或传输层的协议，比如SYN洪泛攻击（SYN flood）或Ping of Death，旨在消耗目标系统的处理能力。
  
  Application Layer Attacks（应用层攻击）：
  针对特定应用程序的攻击，如HTTP洪泛攻击，模仿正常用户行为但意图耗尽应用资源。
  ```

- **防范**：使用DDoS防护服务（如Cloudflare或AWS Shield）、配置适当的网络规则来过滤流量、保持冗余网络和资源。

##### 2. SQL注入

- **描述**：攻击者在SQL查询中注入恶意代码，从而控制数据库。
- **防范**：使用参数化查询、限制数据库权限、定期审计SQL查询。

##### 3. 交叉站点脚本（XSS，Cross-Site Scripting）

- **描述**：在用户浏览器上执行非经请求的脚本，窃取信息或者仿冒用户。

  1. **存储型 XSS (Stored XSS)** 存储型 XSS 攻击发生时，恶意脚本被永久地存储在目标服务器上，例如在数据库、消息论坛、访客日志、评论区等。当其他用户浏览到含有恶意脚本的页面时，就会受到攻击。
  2. **反射型 XSS (Reflected XSS)** 反射型 XSS 发生时，恶意脚本并不会存储在服务器上，而是通过用户点击一个恶意链接或提交表单触发的。该恶意脚本通常作为请求的一部分发送到服务器端，然后服务器端将其作为响应的一部分返回，并在用户的浏览器上执行。

  后果：

  - 盗取用户的 cookies 和会话令牌。
  - 对用户界面进行篡改。

- **防范**：对用户输入进行过滤和转义、设置HTTPOnly和Secure标志的Cookies、内容安全策略（CSP）。

##### 4. 会话劫持和固定会话攻击

- **描述**：攻击者尝试截获或接管用户的会话令牌来仿冒用户。

  操作方式：

  - 监听不安全的网络流量来捕获未加密的会话token。
  - 使用XSS攻击将用户的会话cookie发送到攻击者控制的服务器。

- **防范**：使用HTTPS、定期更换会话ID、实施合理的会话超时机制。

##### 5. 中间人攻击（MITM）

- **描述**：攻击者在通信双方之间截获或篡改数据。
- **防范**：始终使用加密协议（例如TLS/SSL）、公共Wi-Fi的VPN连接、端点认证。

### 十五、云原生技术

发展历程：

- 物理机部署：早期一般将应用程序直接部署到物理机上，部署方式简单，但是不能为应用程序定义资源和使用边界，很难合理的分配计算资源，应用程序之间会产生影响。
- 虚拟机部署：在一台物理机上运行多个虚拟机，每个虚拟机都是一个独立的环境，这会导致额外的操作系统开销。
- 容器化部署：容器化部署与虚拟机类似，不同点是容器之间共享操作系统，每个容器之间拥有自己的**文件系统、CPU、内存、进程空间**，应用程序需要的资源都被容器包装，并且和底层基础架构解耦，可以实现跨服务器跨操作系统进行部署。

云原生（Cloud Native）是一种构建和运行应用程序的方法，它充分利用了云计算的优势。"云原生"技术使得组织可以构建和运行可在公共云、私有云或混合云环境中无缝运作的应用程序。这种方法并不是指特定的技术或工具，而是一套技术理念和最佳实践的集合，旨在充分发挥现代云计算模型的潜力。

1. **容器化**：应用程序及其运行环境被封装在容器中。容器是轻量级的、可移植的、自给自足的软件执行环境，可以确保软件在不同的计算环境中以相同的方式运行。
2. **微服务架构**：应用被设计为一系列小型、独立的服务，每个服务负责执行单一业务功能。这些服务可以独立部署、扩展和管理。
3. **动态管理**：利用自动化系统进行资源的分配和优化，常见的有Kubernetes等容器编排平台。这些系统能够在多个服务器和环境中自动部署、维护和扩展容器化应用。
4. **敏捷性和持续交付**：云原生应用支持快速迭代开发和发布，促进持续集成/持续部署（CI/CD）的实践，从而加速产品上市时间并提高响应市场变化的能力。
5. **可伸缩性**：云原生应用能够根据负载自动扩展或收缩资源，从而有效地利用云资源，并对突然的流量变化做出快速响应。

流程：

> ### 步骤 1: 创建并容器化您的应用程序
>
> 首先，你需要有一个应用程序。我们以一个简单的 Node.js 应用为例，以下是 `app.js` 的代码：
>
> ```javascript
> const http = require('http');
> 
> const requestHandler = (request, response) => {
>     console.log(request.url);
>     response.end('Hello Kubernetes!');
> };
> 
> const server = http.createServer(requestHandler);
> 
> server.listen(8080, () => {
>     console.log(`Server is running on 8080`);
> });
> ```
>
> ### 步骤 2: 编写 Dockerfile
>
> 接着，为你的应用编写一个 Dockerfile 来构建一个 Docker 镜像。保存为 `Dockerfile` 文件：
>
> ```dockerfile
> # 使用 Node.js 官方镜像作为构建环境
> FROM node:14
> 
> # 创建 app 目录
> WORKDIR /usr/src/app
> 
> # 安装 app 依赖
> # 使用通配符确保 package.json 和 package-lock.json 都被复制
> # 在这个示例中，假设你已经有了一个 package.json 和相应的 package-lock.json
> COPY package*.json ./
> 
> RUN npm install
> 
> # 打包 app 源代码
> COPY . .
> 
> # 应用绑定的端口
> EXPOSE 8080
> 
> # 定义环境变量
> ENV NAME World
> 
> # 运行命令
> CMD [ "node", "app.js" ]
> ```
>
> ### 步骤 3: 构建 Docker 镜像
>
> 在包含 Dockerfile 的目录中执行以下命令来构建镜像：
>
> ```sh
> docker build -t my-nodejs-app .
> ```
>
> ### 步骤 4: 推送镜像到镜像仓库
>
> 假设你要将镜像推送到 Docker Hub，你需要给镜像打上标签并推送它：
>
> ```sh
> docker tag my-nodejs-app yourusername/my-nodejs-app:v1
> docker push yourusername/my-nodejs-app:v1
> ```
>
> ### 步骤 5: 编写 Kubernetes 配置
>
> 现在编写 Kubernetes 配置来定义如何在集群中运行镜像。创建一个名为 `deployment.yaml` 的文件：
>
> ```yaml
> apiVersion: apps/v1
> kind: Deployment
> metadata:
>   name: my-nodejs-app
> spec:
>   replicas: 2 # 你想要运行的副本数
>   selector:
>     matchLabels:
>       app: my-nodejs-app
>   template:
>     metadata:
>       labels:
>         app: my-nodejs-app
>     spec:
>       containers:
>       - name: my-nodejs-app
>         image: yourusername/my-nodejs-app:v1 # 替换成你的镜像名称
>         ports:
>         - containerPort: 8080
> ```
>
> 还可以创建一个 `service.yaml` 文件来定义外部访问您的应用程序的规则：
>
> ```yaml
> apiVersion: v1
> kind: Service
> metadata:
>   name: my-nodejs-service
> spec:
>   selector:
>     app: my-nodejs-app
>   type: LoadBalancer # 使用负载均衡器暴露服务
>   ports:
>     - protocol: TCP
>       port: 80
>       targetPort: 8080
> ```
>
> ### 步骤 6: 在 Kubernetes 中部署应用程序
>
> 最后，在 Kubernetes 集群上部署你的应用和服务：
>
> ```yaml
> kubectl apply -f deployment.yaml
> kubectl apply -f service.yaml
> ```
>
> 如果一切正常，你的 Node.js 应用现在应该是由两个副本组成的部署，并通过负载均衡器对外提供服务。
>
> 要检查部署情况，可以使用以下命令：
>
> ```sh
> kubectl get deployments
> kubectl get pods
> kubectl get services
> ```

### 十七、基于角色的访问控制模型（RBAC）

在 Casbin 中，策略规则通常存储在称为 "policy" 的表或文件中。这个 "rule" 表（或者称为 “policy storage”）是用来保存 Casbin 访问控制策略的细节信息。使用 SQL 语法表示：

```sql
CREATE TABLE casbin_rule (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    ptype VARCHAR(255) NOT NULL,
    v0 VARCHAR(255) NOT NULL,
    v1 VARCHAR(255) NOT NULL,
    v2 VARCHAR(255) DEFAULT NULL,
    v3 VARCHAR(255) DEFAULT NULL,
    v4 VARCHAR(255) DEFAULT NULL,
    v5 VARCHAR(255) DEFAULT NULL
);
```

- `id`：主键，唯一标识每条策略规则。
- `ptype`：策略类型，例如 `p` 表示策略 (policy)，`g` 表示角色继承关系 (grouping policy)。
- `v0` - `v5`：这些字段用来存储策略的参数。根据具体的 Casbin 模型和策略的复杂性，可以使用不同数量的参数，通常 v0 表示 subject（主体），v1 表示 object（对象），v2 表示 action（操作）。其余字段可用于存储其他条件、角色或权限等，具体取决于你的 Casbin 模型配置。

通常是一个三元素策略（subject, object, action）

- `v0` 可以是用户名或用户组。
- `v1` 可以是资源，例如文件、数据库表或者 URL。
- `v2` 可以是对该资源的操作，例如 read、write 或 delete。

![image-20240315141533608](https://gitee.com/xu_zuyun/picgo/raw/master/img/image-20240315141533608.png)

### 十八、如何设计幂等性？

- 1. 使用唯一标识符

  为每个操作请求分配一个唯一标识符（如 UUID 或其他形式的 token）。在执行操作之前，系统首先检查这个标识符是否已经存在，如果存在，则跳过操作；否则，进行操作并记录这个标识符。

- 2. 数据库约束

  利用数据库的唯一索引或主键约束来阻止重复的记录。例如，在数据库中插入记录时，如果记录的关键字段已经存在，数据库将拒绝新的插入操作。

- 3. 状态机

  对资源状态进行建模，并确保转换规则使得重复的操作不会改变资源的最终状态。例如，如果一个对象已经处于“已处理”状态，则不管再收到多少次处理请求，它都将保持“已处理”状态。

### 十九、内存映射

内存映射（Memory Mapping，简称 mmap）是一种在程序中处理文件的高效方式。这种技术允许程序将一个磁盘上的文件或其他对象直接映射到进程的地址空间中，使得开发人员可以像访问普通内存数组一样来操作这个文件，而不需要使用传统的文件读写操作如`read`和`write`。

当一个文件被内存映射后，操作系统会负责将文件内容加载到物理内存中，并为它在虚拟地址空间中提供一个直接的访问界面。对于这部分内存的读写操作，则通过内存访问指令直接完成，无需额外的系统调用，这能够显著提升文件读写操作的性能。

内存映射的优点包括：

1. **性能提升：** 内存映射文件的I/O操作可能比标准的文件I/O更快，因为它们利用了操作系统的页缓存以及潜在的懒加载机制。
2. **便捷的数据访问：** 映射之后的文件可以像普通的内存区域一样进行字节级别的随机访问。
3. **简化编程模型：** 由于可以直接通过指针访问文件内容，所以在某些情况下可以简化代码逻辑。

### 二十、文件存储、块存储、对象存储

##### 文件存储 (File Storage)

- **概念**: 文件存储是一种基于文件和目录层次结构的存储方法。用户和应用程序可以通过操作系统提供的文件系统接口来保存、组织和检索数据。
- 特点
  - 提供了一个标准的文件导航系统，包括文件夹和子文件夹。
  - 支持文件级访问控制和权限管理。
  - 可以通过`网络共享协议`（例如NFS、SMB/CIFS）跨网络进行文件共享。
- 场景：文件服务器、HTML

##### 块存储 (Block Storage)

- **概念**: 块存储将存储卷分割成固定大小的块，每个块都可以独立地被当作硬盘来使用。操作系统可以格式化这些块并在其上安装文件系统。
- 特点
  - 每个存储块都像磁盘驱动器一样工作，可以单独格式化和挂载。
  - 提供了高性能的I/O处理，适合数据库、虚拟机文件系统等需要快速读写的场景。
  - 常见于SAN（存储区域网络）环境中，通常通过iSCSI、Fibre Channel等协议提供访问。
- 场景：数据库、高性能计算

##### 对象存储 (Object Storage)

- **概念**: 对象存储用于管理数据作为单独的单位，称为对象。每个对象包含数据本身、变量长度的元数据以及一个全球唯一的标识符（通常是URL）。
- 特点
  - 无需复杂的层次结构或文件系统；对象可以在扁平的地址空间中存储和检索。
  - 允许用户存储和处理大量非结构化数据。
  - 适合云存储和大数据应用，如Amazon S3、Google Cloud Storage和OpenStack Swift等。
- 场景：云存储服务、图床
