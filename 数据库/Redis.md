## Redis

### 1、什么是redis

​		redis是一种基于内存的数据库,对数据的读写操作都是在内存中完成的，因此读写速度非常快，常用于缓存、消息队列、分布式锁等场景。

- （1）完全基于内存操作，数据都存在内存中
- （2）采用单线程，避免了不必要的上下文切换带来的性能问题，也不用考虑锁的问题
- （3）基于非阻塞的io多路复用机制
- （4）数据结构简单，对数据操作简单

```markdown
## redis具备高性能
用户第一次访问mysql中的某些数据，因为是从硬盘上读取的，所以过程会比较慢。将该用户访问的数据缓存在redis中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了，操作redis就是直接操作内存，注意redis和mysql双写一致性的问题。
## redis具备高并发
单台设备的redis的QPS（每秒钟处理完请求的次数）是mysql的十倍，所以redis能够承受的请求是远远大于mysql的，因此可以考虑把数据库中的部分数据转移到缓存中去。
```

```markdown
## 决定何时使用缓存
在数据经常被读取但很少被修改时，考虑使用缓存。由于缓存数据存储在易失性内存中，缓存服务器不适合用于持久化数据。例如，如果缓存服务器重新启动，内存中的所有数据都会丢失。因此，重要的数据应保存在持久化数据存储中。

## 过期策略
实施过期策略是一个好的做法。一旦缓存数据过期，它将从缓存中删除。当没有过期策略时，缓存数据将永久存储在内存中。建议不要将过期日期设置得太短，否则系统会过于频繁地从数据库重新加载数据。同时，也不建议将过期日期设置得太长，以免数据变得陈旧。

## 一致性
这涉及保持数据存储和缓存的同步。由于数据存储和缓存上的数据修改操作不在单个事务中，所以可能发生不一致。在跨多个地区进行扩展时，保持数据存储和缓存之间的一致性是具有挑战性的。有关详细信息，请参考Facebook发表的题为《Scaling Memcache at Facebook》的论文[7]。

## 减轻故障
“单点故障（SPOF）是系统的一部分，如果它发生故障，将导致整个系统停止工作”[8]。因此，建议在不同的数据中心中使用多个缓存服务器，以避免单点故障。另一个推荐的方法是通过一定百分比进行过量配置所需的内存。这样可以提供一个缓冲区，以应对内存使用量增加的情况。

## 淘汰策略
一旦缓存已满，任何向缓存中添加项的请求都可能导致现有项被移除。这被称为缓存淘汰。最近最少使用（LRU）是最常见的缓存淘汰策略。其他淘汰策略，如最不经常使用（LFU）或先进先出（FIFO），可根据不同的使用情况采用。
```

#### Jedis和 Redisson是什么？

Jedis和 Redisson 都是Java中对Redis操作的封装。Jedis 只是简单的封装了 Redis 的API库，可以看作是Redis客户端，它的方法和Redis 的命令很类似。Redisson 不仅封装了 redis ，还封装了对更多数据结构的支持，以及锁等功能相比于Jedis 更加大。但Jedis相比于Redisson 更原生一些，更灵活。

#### 代码

```go
package main

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"github.com/go-redis/redis/v8"
	_ "github.com/lib/pq" // PostgreSQL驱动
	"log"
)
var ctx = context.Background()

// 假设我们的用户结构体如下：
type User struct {
	ID   int64  `json:"id"`
	Name string `json:"name"`
}

// 初始化Redis客户端
func initRedisClient() *redis.Client {
	rdb := redis.NewClient(&redis.Options{
		Addr:     "localhost:6379",
		Password: "", // 无密码
		DB:       0,  // 使用默认DB
	})
	return rdb
}

// 初始化数据库连接
func initDB() *sql.DB {
	db, err := sql.Open("postgres", "user=username dbname=yourdbname sslmode=disable")
	if err != nil {
		log.Fatal(err)
	}
	return db
}

// 获取用户数据的函数，尝试先从Redis缓存中获取，如果没有则查询数据库
func getUser(rdb *redis.Client, db *sql.DB, userID int64) (*User, error) {
	var user User
	key := fmt.Sprintf("user:%d", userID)

	// 尝试从Redis中获取用户信息
	val, err := rdb.Get(ctx, key).Result()
	if err == redis.Nil {
		// 缓存未命中，从数据库获取
		err := db.QueryRow("SELECT id, name FROM users WHERE id = $1", userID).Scan(&user.ID, &user.Name)
		if err != nil {
			return nil, err
		}
		
		// 序列化用户信息并保存到Redis，设置过期时间
		userJSON, err := json.Marshal(user)
		if err != nil {
			return nil, err
		}
		rdb.Set(ctx, key, userJSON, 0) // 这里可设置具体的过期时间
	} else if err != nil {
		return nil, err
	} else {
		// 如果Redis中有缓存，反序列化得到用户信息
		err = json.Unmarshal([]byte(val), &user)
		if err != nil {
			return nil, err
		}
	}

	// 返回用户信息
	return &user, nil
}

func main() {
	// 初始化Redis客户端和数据库连接
	rdb := initRedisClient()
	defer rdb.Close()

	db := initDB()
	defer db.Close()

	// 获取用户信息
	user, err := getUser(rdb, db, 1) // 假设我们想获取ID为1的用户
	if err != nil {
		log.Fatal(err)
	}

	fmt.Printf("User: %#v\n", user)
}
```

### 2、五种数据结构

![在这里插入图片描述](https://gitee.com/xu_zuyun/picgo/raw/master/img/1373333691054da99a2f98120c430b03.png)

- String类型的应用场景：缓存对象、常规计数、分布式锁、共享session信息等。
- List类型的应用场景：消息队列（2 problems：生产者需要自行实现全局唯一ID 不能以消费组形式消费数据
- Hash类型：缓存对象、购物车
- set类型：集合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
- Zset类型：排序场景，比如排行榜、电话和姓名排序等 。

##### ziplist

- 压缩列表 ziplist 是为 Redis 节约内存而开发的。ziplist 是由一系列特殊编码的内存块构成的列表(像内存连续的数组，但每个元素长度不同)， 一个 ziplist 可以包含多个节点（entry）。
- ziplist 是一个特殊的双向链表, 特殊之处在于：没有维护双向指针:prev next；而是存储上一个 entry的长度和 当前entry的长度，通过长度推算下一个元素在什么地方。牺牲读取的性能，获得高效的存储空间，因为(简短字符串的情况)存储指针比存储entry长度 更费内存。
- ziplist使用局限性:;字段、值比较小，才会用ziplist
- List和Map开始状态都是ziplist，后期会变成quicklist 和 hashmap

##### **①String类型底层实现**

SDS结构(Simple Dynamic String)

len：记录了字符串长度（获取字符串长度时间复杂度为O(1))
alloc:分配给字符数组的空间长度。因此可以通过alloc - len计算出剩余的空间大小，可以用来判断空间是否满足修改需求，如果不满足，则会自动将SDS的空间扩展至执行修改所需的大小，然后才执行实际的修改操作即SDS会自动扩展空间
flags：用来表示不同类型的SDS
buf[]：字符数组，用来保存实际数据

```bash
SET mykey "Hello, World!"
MSET key1 "value1" key2 "value2"
SETEX mykey 60
EXPIRE mykey 60

GET key1
MGET key1 key2

SET counter 100
INCR counter
DECR counter
```

##### ②List列表类型底层实现

压缩列表ziplist + 双向链表 quicklist

出现如下情况时会发生转换：

- 试图往列表新添加一个字符串值，且这个字符串的长度超过 server.list_max_ziplist_value （默认值为 64 ）。
-  ziplist 包含的节点超过 server.list_max_ziplist_entries （默认值为 512 ）。

##### ③Map哈希表类型底层实现

1> 数据较少时：ziplist

ziplist 是一个紧凑的双向链表，它将所有的元素紧密地排列在一起，field 和 value 是连续存放的，即一个 field 后面紧跟着对应的 value，然后是下一个 field，再是下一个 value。

2> 数据较多时：hashtable

结构：一个数组和多个散列桶（buckets链表）

冲突：redis采用`链式哈希来解决哈希冲突`，`当有两个以上数量的key被分配到了哈希表中同一个哈希桶上时，称这些key发生了冲突`，`被分配到了同一个哈希桶上的多个节点可以用单向链表连接起来`

扩容：

**普通rehash：**采用两个hash表，

- 给哈希表2分配空间，一般会比哈希表1大两倍
- 将哈希表1的数据迁移到哈希表2中
- 迁移完成后，哈希表1的空间会释放，并把哈希表2设置为哈希表1，然后在哈希表2新创建一个空白的哈希表，为下一次rehash做准备。

**渐进式rehash：**当满足一定条件（负载因子，是否在快照）时进入rehash状态

- rehash进行期间，每次哈希表元素进行新增、删除、查找或者更新操作时，redis除了会执行对应的操作之外，还会顺序将哈希表1中索引位置上的所有key-value迁移到哈希表2上

```bash
HSET user:1000 name "Alice"
HSET user:1000 email "alice@example.com"
HMSET user:1001 name "Bob" age "27" gender "male"

HGETALL user:1000
HGET user:1000 name

HDEL user:1000 email
HLEN user:1000 // 获得Hash中字段的数量。
```

##### ④Set集合底层实现

- 1）Set对象的编码可以是 intset 或者 hashtable（键为元素，值为null）；

  当Set内所有元素都是整数、个数小于512个的情况下使用intset，否则使用hashmap

- 2）intset 编码的集合对象使用整数集合作为底层实现；

- 3）hashtable 编码的集合对象使用字典(map)作为底层实现；

##### ⑤Zset有序集合底层实现

底层实现用到了跳表，跳表的优势是能支持平均O(log N)复杂度的节点查找

![在这里插入图片描述](https://gitee.com/xu_zuyun/picgo/raw/master/img/d1dde033e6844aeab053298a26c03d94.png)

##### 其他特殊的数据类型

```
1、Bitmap：位图，可以认为是一个以位为单位数组，数组中的每个单元只能存0或者1，数组的下标在 Bitmap 中叫做偏移量。Bitmap的长度与集合中元素个数无关，而是与基数的上限有关。

2、Hyperloglog。HyperLogLog 是用来做基数统计的算法，其优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。典型的使用场景是统计独立访客。
```

### 3、redis线程模型

#### Reactor多线程模式

- Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件
- 当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor
- SubReactor将连接加入到连接队列进行监听，并创建Handler进行各种事件处理
- 当有新的事件发生，SubReactor就会调用对应的Handler处理
- Handler通过read读取数据，分发给后面的worker线程处理
- worker线程池分配独立的worker线程进行处理，并返回结果
- handler收到响应结果后，再通过send将结果返回给client

![img](https://img-blog.csdnimg.cn/img_convert/d93d86381f989a006d1fe248db67b516.webp?x-oss-process=image/format,png)

**Redis基于Reactor模式开发了网络事件处理器**，这个处理器被称为文件事件处理器。它的组成结构为4部分：多个套接字、IO多路复用程序、文件事件分派器、事件处理器。因为**文件事件分派器队列的消费**是单线程的，所以Redis才叫单线程模型。

- 使用I/O多路复用（multiplexing）程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的handler。
- 文件事件分派器从队列中接收 I/O  多路复用程序传来的socket，并根据socket产生的事件类型（包括读取请求（readable events）、写入确认（writable events）等），调用相应的事件处理器（即具体的回调函数）。当上一个socket产生的事件被对应事件处理器执行完后，文件事件分派器才会向队列拉取下一个要处理的socket，保证socket操作一定不会并发的执行，保证线程安全。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/format,png-20240302152226286.png)

##### 注意redis的单线程只局限于网络IO和执行命令

redis单线程是指[**接受客户端请求 -> 解析请求 -> 进行数据读写操作 -> 发送数据给客户端**]这个过程是由一个顺序串行的主线程来完成的
redis程序并不是单线程的，redis在启动的时候，会启动后台线程的。redis会为很耗时的任务创建单独的线程来处理，如关闭文件、AOF刷盘、释放内存

##### redis为什么单线程还这么快？

redis的大部分操作都在内存中完成，读写速度快，并且采用了高效的数据结构
redis采用单线程模型可以避免多线程之间的竞争
redis采用了I/O多路复用机制处理大量的客户端socket请求，允许内核中存在多个监听socket和已连接socket，实现一个redis线程处理多个IO流的效果。

```
IO多路复用（Multiplexing）是一种技术，它允许单个进程或者线程监控多个文件描述符（file descriptors），以便能够在这些描述符之一准备好进行IO操作时，立即得到通知并进行相应的读写操作。
```

##### redis为什么不使用多线程？

> 1. 使用 Redis 时，几乎不存在 CPU 成为瓶颈的情况， Redis 主要受限于内存和网络
> 2. 使用了单线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗

##### Redis6.0 为什么要引入多线程呢？

- 可以充分利用服务器CPU的多核资源，而主线程明显只能利用一个
- 多线程任务可以分摊 Redis 同步 IO 读写负荷，降低耗时

### 4、redis持久化

当redis重启后，内存中的数据就会丢失，那为了保证内存中的数据不会丢失，会把数据存储到磁盘

- AOF日志：每执行一条写操作命令，就把该命令以追加的方式写入到一个文件里

```markdown
## 含义
开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到 AOF 缓冲区 server.aof_buf 中，然后再写入到 AOF 文件中（此时还在系统内核缓存区未同步到磁盘），最后再根据持久化方式（ fsync策略）的配置来决定何时将系统内核缓存区的数据同步到硬盘中的。

只有同步到磁盘中才算持久化保存了，否则依然存在数据丢失的风险，比如说：系统内核缓存区的数据还未同步，磁盘机器就宕机了，那这部分数据就算丢失了。

默认的文件名是 appendonly.aof。
## 五个步骤
    命令追加（append）：所有的写命令会追加到 AOF 缓冲区中。
    文件写入（write）：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用write函数（系统调用），write将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。
    文件同步（fsync）：AOF 缓冲区根据对应的持久化方式（ fsync 策略）向硬盘做同步操作。这一步需要调用 fsync 函数（系统调用）， fsync 针对单个文件操作，对其进行强制硬盘同步，fsync 将阻塞直到写入磁盘完成后返回，保证了数据持久化。
    文件重写（rewrite）：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。
    重启加载（load）：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。
## 三种策略
    1. appendfsync always：主线程调用 write 执行写操作后，后台线程（ aof_fsync 线程）立即会调用 fsync 函数同步 AOF 文件（刷盘），fsync 完成后线程返回，这样会严重降低 Redis 的性能（write + fsync）。
    2. appendfsync everysec：主线程调用 write 执行写操作后立即返回，由后台线程（ aof_fsync 线程）每秒钟调用 fsync 函数（系统调用）同步一次 AOF 文件（write+fsync，fsync间隔为 1 秒）
    3. appendfsync no：主线程调用 write 执行写操作后立即返回，让操作系统决定何时进行同步，Linux 下一般为 30 秒一次（write但不fsync，fsync 的时机由操作系统决定）。
## AOF重写
    AOF 文件重写期间，Redis 会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。
```

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/v2-3fa0daf10399d7ea84e51025571ac155_1440w.png)

- RDB快照：将某一时刻的内存数据，以二进制的方式写入磁盘

```
RDB快照就是记录某一个瞬间的内存数据，记录的是实际数据

Redis 提供了两个命令来生成 RDB 快照文件：
    save : 同步保存操作，会阻塞 Redis 主线程；
    bgsave : fork 出一个子进程，子进程执行，不会阻塞 Redis 主线程，默认选项。
```

- 混合持久化方式 ：redis4.0新增的方式，集成了AOF和RDB的优点

```
就是AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式的增量数据(RDB优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。)
```

##### RDB更优秀的地方：

- RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份
- 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。

##### AOF更优秀的地方：

- RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的。
- 可以直接操作 AOF 文件来解决一些问题。比如，如果执行`FLUSHALL`命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态

##### 如何选择

- Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。
- 不建议单独使用 AOF，因为时不时地创建一个 RDB 快照可以进行数据库备份、更快的重启以及解决 AOF 引擎错误。
- 如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。

### 5、redis集群

#### 单点部署

在单点部署中，Redis运行在单个节点上。这是最简单的部署方式，但它的容错能力非常有限。如果该节点发生故障，所有的数据将会丢失。

#### 集群三种模式

- 主从复制

主服务器可以进行读写操作`对客户端来说`，但发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读`对客户端来说`，接受主服务器同步过来写操作命令，然后执行这条命令。

```markdown
1. slave启动后，向master发送SYNC命令，master接收到SYNC命令后通过bgsave保存快照（即上文所介绍的RDB持久化），并使用缓冲区记录保存快照这段时间内执行的写命令
2. master将保存的快照文件发送给slave，并继续记录执行的写命令 
3. slave接收到快照文件后，加载快照文件，载入数据 
4. master快照发送完后开始向slave发送缓冲区的写命令，slave接收命令并执行，完成复制初始化
5. 此后master每次执行一个写命令都会同步发送给slave，保持master与slave之间数据的一致性

缺点：
     不具备自动容错与恢复功能，master或slave的宕机都可能导致客户端请求失败，要等待机器重启或手动切换客户端IP才能恢复
     master宕机，如果宕机前数据没有同步完，则切换IP后会存在数据不一致的问题
     难以支持在线扩容，Redis的容量受限于单机配置
```

- 哨兵模式

![在这里插入图片描述](https://gitee.com/xu_zuyun/picgo/raw/master/img/3bf6b599eb874fbcb7f5bad806e164f6.png)

使用redis主从服务的时候，当redis的主从服务器出现故障宕机时，需要手动进行恢复。在主从集群基础上添加哨兵节点或哨兵集群，用于监控master节点健康状态，通过投票机制选择slave成为主节点

```markdown
## 哨兵职责：
1. 定期（一般10s一次，当master被标记为主观下线时，改为1s一次）向master和slave发送INFO命令
2. 定期向master和slave的_sentinel_:hello频道发送自己的信息
3. 定期（1s一次）向master、slave和其他哨兵发送PING命令
     
哨兵认为master客观下线后，故障恢复的操作需要由选举的领头哨兵来执行，选举采用Raft算法
选出领头哨兵后，领头者开始对系统进行故障恢复，从出现故障的master的从数据库中挑选一个来当选新的master,选择规则如下：
     所有在线的slave中选择优先级最高的，优先级可以通过slave-priority配置
     如果有多个最高优先级的slave，则选取复制偏移量最大（即复制越完整）的当选
     如果以上条件都一样，选取id最小的slave
```

- 切片集群模式

主从模式和哨兵模式解决了并发读的问题，但没有解决并发写的问题，redis缓存数据量大到一台服务器无法缓存时，需要使用redis切片集群，Cluster模式实现了Redis的分布式存储，即每台节点存储不同的内容，来解决在线扩容的问题，从而提高redis服务的读写性能。redis集群采用哈希槽，一个切片集群共有16384个哈希槽，每个键值对都会根据它的key，被映射到一个哈希槽中。

集群中，节点间数据同步是通过Gossip协议实现的。每个节点都维护一个gossip协议的列表，保存了所有节点的信息以及当前节点负责的槽信息。每秒钟，每个节点都会随机选择几个节点，向它们发送包含本节点信息的Gossip消息，让它们了解到当前节点维护的槽信息。节点接收到Gossip消息后，会更新自己的槽信息，保持所有节点信息的一致性。

```markdown
## 特点：
所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽
节点的fail是通过集群中超过半数的节点检测失效时才生效
客户端与redis节点直连,不需要中间代理层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可
## 流程：
 在Redis的每个节点上，都有一个插槽（slot），取值范围为0-16383
 当我们存取key的时候，Redis会根据CRC16的算法得出一个结果，然后把结果对16384求余数，这样每个key都会对应一个编号在0-16383之间的哈希槽。
 Cluster模式集群节点最小配置6个节点(3主3从，因为需要半数以上)，其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。
 ## 客户端
 客户端可以连接集群中任意一个Redis 实例，发送读写命令，如果当前Redis 实例收到不是自己负责的Slot的请求时，会将该slot所在的正确的Redis 实例地址返回给客户端。
客户端收到后，自动将原请求重新发到这个新地址，自动操作，外部透明。
```

正常的心跳数据包携带节点的完整配置，它能以幂等方式来更新配置。如果采用 16384 个插槽，占空间 2KB （16384/8）；如果采用 65536 个插槽，占空间 8KB (65536/8)。

![1f043d9e86c9381d3d46341fe7f0bd4d](https://gitee.com/xu_zuyun/picgo/raw/master/img/1f043d9e86c9381d3d46341fe7f0bd4d.jpg)

Redis主节点的哈希槽配置信息是通过 bitmap 来保存的，所以，插槽数偏低的话， 填充率会降低，压缩率会升高。综合下来，从心跳包的大小、网络带宽、心跳并发、压缩率等维度考虑，16384 个插槽更有优势且能满足业务需求。

**脑裂**

由于网络问题，集群节点间失去联系。主从数据不同步，重新平衡选举，产生两个主服务。等网络恢复，旧主节点就会降级为从节点，再与新主节点进行同步复制

```markdown
脑裂导致数据丢失怎么办?
    min-slaves-to-write x，主节点必须要有至少x个从节点连接，如果少于这个数，主节点就会禁止写数据
    min-slaves-max-lag x，主从数据复制和同步的延迟不能超过x秒，如果超过，主节点会禁止写数据
```

### 6、redis过期删除和内存淘汰

每当我们对一个key设置了过期时间，redis就会把该key带上过期时间存储到一个`过期字典`，也就是`过期字典`保存了数据库所有key的过期时间。当我们查询一个key时，redis在过期字典中检查是否被当前时间超过

#### 定时删除策略 

 `在设置key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。`

#### 惰性删除策略

`不主动删除过期键，每次从数据库访问key时，检测key是否过期，如果过期就删除该key`

#### 定期删除策略

 `每隔一段时间，随机从数据库中取出一定数量的key进行检查，并删除其中的过期key`

优点：通过限制删除操作执行的时长和频率，减少删除操作对CPU的影响，同时也能删除一部分过期数据，减少过期键对空间的无效占用。

#### redis内存淘汰

- 不进行数据淘汰的策略： noeviction，当运行内存超过最大设置内存时，不淘汰任何数据，而是不提供服务，直接返回错误
- 进行数据淘汰的策略：可进一步细分为`在设置了过期时间的数据中进行淘汰`和`在所有数据范围内进行淘汰`

##### 1、LRU算法

 redis实现的是一种`近似LRU算法`，它的`实现方式是在redis的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。每次随机选取一批数据进行LRU淘汰，而不是针对所有的数据，通过牺牲部分准确率来提高LRU算法的执行效率。

```markdown
## 优点：
- 不用为所有的数据维护一个大链表，节省了空间占用
- 不用在每次数据访问时都移动链表项，提升缓存性能
## 缺点：
`无法解决缓存污染问题`，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在redis缓存中很长一段时间，造成缓存污染。
```

##### 2、LFU（least frequently used)

最近最不常用的，LRU 根据数据访问次数来淘汰数据的，核心思想是`如果数据过去被访问多次，那么将来被访问的频率也更高`

LFU算法的实现没有使用额外的数据结构，复用了redisObject数据结构的lru字段，把这24bit空间拆分成两部分去使用。

![99fbfc78c42a6932bd1b1fd50758f8ba](https://gitee.com/xu_zuyun/picgo/raw/master/img/99fbfc78c42a6932bd1b1fd50758f8ba.png)

- 由于记录时间戳在空间被压缩到16bit，所以LFU改成以分钟为单位，大概45.5天会出现数值折返，比LRU时钟周期还短。

- 低位的8bit用来记录热度值（counter），8bit空间最大值为255，无法记录数据在访问总次数（只是通过某些操作将0到无穷映射到0到255，[参考](https://blog.csdn.net/vivo_tech/article/details/131572136)）。

  ![image-20240320142623937](https://gitee.com/xu_zuyun/picgo/raw/master/img/image-20240320142623937.png)

##### 选择：

如果业务数据的访问较为均匀，OPS或CPU利用率一般不会出现周期性的陡升或陡降，数据没有体现出相对的“冷热”特性，即建议采用LRU算法，可以满足一般的运维需求。

如果业务具备很强时效性，在活动推广或大促期间，业务某些数据会突然成为热点数据，，建议一定要配置成LFU算法。

### 7、Redis缓存设计

##### 缓存雪崩

```markdown
## 定义
但是当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在redis中处理，那么全部请求就都直接访问数据库，从而导致数据库的压力骤增，严重的会使数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩
## 解决方法
    将缓存失效时间随机打散
    设置缓存不过期：后台服务来更新缓存数据
```

##### 缓存击穿

```markdown
## 定义
业务中通常会有几个数据被频繁的访问，比如秒杀活动，这类被频繁访问的数据称为热点数据。如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，从而直接访问数据库，数据库很容易被高并发的请求冲垮。
## 解决方法
    互斥锁方案，保证同一时间只有一个业务线程请求缓存。
    不给热点数据设置过期时间，即后台异步更新缓存重新设置过期时间。
```

**缓存穿透**

```markdown
## 定义
当用户访问的数据，既不在缓存中，也不在数据库中，即请求缓存和数据库都找不到要访问的数，没办法构建缓存数据来服务后续的请求，当有大量的请求到来时，数据库压力骤增
## 原因
    业务误操作
    黑客恶意攻击
## 解决方法
`非法请求的限制：需要在API入口处判断请求参数是否合理，是否含有非法值`
`设置空值或默认值：针对查询的数据，在缓存中设置一个空值或默认值，返回给应用，从而不会继续查询数据库。`
`在写入数据库数据时，使用布隆过滤器来做个标记，可以在业务线程确认缓存失效后，通过查询布隆过滤器来快速判断数据是否存在，如果不存在，不用通过查询数据库来判断数据是否存在。即让请求只查询redis和布隆过滤器，不会查询数据库。`
```

##### 缓存更新策略

- 旁路缓存策略（实际使用）
- 读穿/写穿策略
- 写回策略

```markdown
## 旁路缓存
cache aside策略是最常用的，应用程序直接与数据库、缓存交互。并负责对缓存维护，该策略又可以细分为读策略和写策略
写策略的步骤：
    先更新数据库中的数据，再删除缓存中的数据（拓展——延迟双删）
读策略的步骤：
    如果读取的数据命中了缓存，则直接返回数据
    如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入缓存，并且返回给用户
## 读写穿透
将cache作为主要数据存储，而cache服务负责将数据写入和读取自db
    写：先查cache，若不存在，直接更新db，若存在，则先更新cache，然后让cache服务自己更新db
    读：从cache中读取数据，有就返回，无就从db加载到cache，然后再返回
## 写回策略
    Write Back（写回）策略在更新数据的时候，只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行，适合写操作较多的场景。
```

![请添加图片描述](https://gitee.com/xu_zuyun/picgo/raw/master/img/d149c48f320e4b3c9c0dcb277b72ec8f.png)

### 8、Redis分布式锁

##### **版本一：使用setnx setex实现

`SET key value NX EX timeOut`: SET mykey "myvalue" NX EX 300

- NX：只有这个key不存才的时候才会进行操作，即 if not exists；

- EX：设置key的过期时间为秒，具体时间由第5个参数决定

- timeOut：设置过期时间保证不会出现死锁【避免宕机死锁】

  ```
  ## 会出现问题：
  （1） 线程1执行业务时间过长导致自己加的锁过期
  （2） 这时线程2进来加锁成功
  （3） 然后线程1业务逻辑执行完毕开始执行del key命令
  （4） 这时就会出现错误删除线程2加的锁
  （5） 错误删除线程2的锁后，线程3又可以加锁成功，导致有两个线程执行业务代码
  ```

##### **版本二：**加入锁标识

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/252de6d567c5446fae5814a4dad5891a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

```
但又会出现问题：比较并删除这两个操作并不是原子命令：
（1） 线程1获取uuid并判断锁是自己的
（2） 准备解锁时出现GC或者其他原因导致程序卡顿无法立即执行Del命令，导致线程1的锁过期
（3） 线程2就会在这个时候加锁成功
（4） 线程1卡顿结束继续执行解锁指令，就会错误删除线程2的锁
```

##### **版本三：**所以我们使用lua脚本

```
lua脚本是一个非常轻量级的脚本语言，Redis底层天生支持lua脚本的执行，一个lua脚本中可以包含多条Redis命令，Redis会将整个lua脚本当作原子操作来执行，从而实现聚合多条Redis指令的原子操作.
```

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/1e11e97281a4467786afb8fd63989752~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

参考：https://juejin.cn/post/7239058077273620536?searchId=202403021455063F65E8E5735F490A3F73

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/960a304e251f95ca3ce069d70fc94834660952a7.jpeg)

```lua
// lua 脚本 —— 减少库存
local counter = redis.call('hget',KEYS[1],KEYS[2]);
if not counter then
return -1,
end;
local result =counter - ARGV[1];if(result>=0)then
redis.call('hset',KEYS[1],KEYS[2],result),return 1;
end;
return 0;
```

```
问题：
在执行业务代码时，由于业务执行时间长，最终可能导致在业务执行过程中，自己的锁超时，然后锁自动释放了，在这种情况下第二个线程就会加锁成功，从而导致数据不一致的情况发生
由于设置的过期时间太短或者业务执行时间太长导致锁过期，但是为了避免死锁问题又必须设置过期时间，那这就需要引入自动续期的功能，即在加锁成功时，*开启一个定时任务，自动刷新Redis加锁key的超时时间， *从而避免上诉情况发生
```

##### **版本四：**Redisson 看门狗

线程去获取锁，获取成功则执行lua脚本，保存数据到redis数据库。如果获取失败: 一直通过while循环尝试获取锁(可自定义等待时间，超时后返回失败)，获取成功后，执行lua脚本，保存数据到redis数据库。Redisson提供的分布式锁是支持锁自动续期的，也就是说，如果线程仍旧没有执行完，那么redisson会自动给redis中的目标key延长超时时间。

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/88cbd656752123b8229c7ed3f04759c3.jpeg)

##### 缺陷

- 当Redis运行在非单一实例模式时（如主从模式、哨兵模式或集群模式）。如果锁持有者的Redis节点出现故障，其它节点可能无法正确识别锁的状态。
- 当一个持有锁的客户端在释放锁之前崩溃或失去与Redis服务器的连接时，可能会导致锁永久性地被保持状态，除非开发者实现了锁的超时或者心跳检测机制。
- 分布式系统中运行的机器可能有时钟偏差，如果依赖时间来管理锁的过期，那么时间同步问题可能会导致锁意外释放或延迟释放。
- Redis分布式锁不是公平的，可能会导致饥饿

### 9、Redis事务

Redis 提供了一个简单的事务功能，它通过WATCH , MULTI, EXEC, DISCARD 四个命令来实现。Redis 的事务可以保证一系列命令的原子性执行，即要么全部执行，要么一个都不执行。

以下是 Redis 事务的基本命令和步骤：

1. **MULTI**：标记一个事务块的开始。之后的所有命令都会被序列化并且按顺序执行。
2. **命令入队**：在 `MULTI` 之后输入的所有命令不会立刻执行，而是被添加到队列中。
3. **EXEC**：执行所有队列中的命令。如果事务在执行前 **被 WATCH 命令标记为监视的键** 没有修改过，那么这些命令将全部执行，否则不执行任何命令。
4. **DISCARD**：取消事务，清空已经入队的所有命令。
5. **WATCH**：监视一个或多个键，如果在事务执行前这些键被其他命令修改了，那么事务将被打断。

Redis 事务的一个重要特性是它遵循 "optimistic locking"（乐观锁）。这意味着，在事务执行期间，系统假定键值不会被其他客户端修改。如果发生了修改，整个事务队列都不会被执行（EXEC 会返回 nil）。

下面是一个简单的 Redis 事务示例：

```
复制代码127.0.0.1:6379> WATCH mykey
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> INCR mykey
QUEUED
127.0.0.1:6379> INCR mykey
QUEUED
127.0.0.1:6379> EXEC
1) (integer) 1
2) (integer) 2
```

在这个例子中，我们首先用 WATCH 命令监视键 `mykey`。然后使用 MULTI 开始一个事务，并且两次入队 INCR 命令来增加 `mykey` 的值。最后，执行 EXEC 运行事务。如果在执行 EXEC 命令之前 `mykey` 的值被其他客户端改变了，EXEC 将返回 nil，事务中的命令都不会被执行。

需要注意的是，Redis 事务不支持回滚。如果命令执行失败，事务中的其余命令仍然会继续执行。这与 SQL 数据库系统中的事务处理有显著差异。此外，Redis 的事务也不支持隔离级别，无法防止脏读、不可重复读和幻读等问题。因此，在某些场合下，可能需要在应用层面上进行额外的控制和设计。

### 10、Redis应用

Redis 默认支持 16 个数据库（Database），编号从 0 到 15。在 Redis 中，每个数据库相互独立，可以在同一实例内使用不同的数据库来存储不同的数据。通过使用 `SELECT` 命令，可以选择使用哪个数据库。例如，使用 `SELECT 1` 命令可以将当前对话的数据库切换到编号为 1 的数据库。在 Redis 中，每个数据库之间的数据是相互隔离的。

- 应用隔离： Redis的每个数据库是独立的，可以将不同的应用数据存储在不同的数据库中，避免应用之间的冲突。
- 备份恢复： 每个数据库都可以通过SAVE、BGSAVE等命令进行备份，可以单独备份某个数据库而不影响其他数据库。

![e77d22609c194fe891150ca065ca02b1](https://gitee.com/xu_zuyun/picgo/raw/master/img/e77d22609c194fe891150ca065ca02b1.png)

利用Redis的单线程（计数器、分布式锁），利用Set（粉丝关注），利用ZSet（排行榜），利用HyperLogLog（uv统计），利用List（消息队列、历史记录），利用BitMap（签到统计）

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/3e73628d2f864f6bad96c8d57300ccec~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

##### 登陆鉴权

（1）系统登录场景，用户输入手机号后，点击发送短信验证码，通过Redis存储前缀 + 手机号作为key，验证码作为value，并设置60秒过期时间。

（2）用户在60秒内进行登录验证，则可以从Redis中获取到验证码，验证相同则登录成功，超过60秒则获取不到验证码值，登录失败。

（3）用户登录后生成token，Redis存储前缀 + token作为key，用户ID作为value，并设置为一天过期。

（4）接下来可以通过token进行鉴权，并获取对应的用户ID。

##### 计数器

```php
redis> set article1 0    //初始化，将article1的点赞数设置为0
"OK"
redis> incr article1    //article1被点赞一次
(integer) 1
redis> decr article1    //article1被取消点赞一次
(integer) 0
redis> incrby article1 2    //通过incrby，可以实现article1被点赞N次
(integer) 2
redis> decrby article1 2    //通过decrby，可以实现article1被取消点赞N次
(integer) 0
```

##### 粉丝关注

Set是一个无序的天然去重的集合，即：Key-Set。此外，Set还提供了求交集、求并集等一系列直接操作集合的方法，非常适合于求共同或单方好友、粉丝、爱好之类的业务场景，实现起来特别方便。

##### 排行榜

Zset（SortedSet），是Set的可排序版，是通过增加一个排序属性score来实现的，适用于排行榜和时间线之类的业务场景，且在高并发场景下具备非常优秀的性能。

##### 防刷

```php
redis> set createorder|userid|1234 “” EX 1 NX    //userid为1234的用户第一次下单成功，设置一秒钟过期
"OK"
redis> set createorder|userid|1234 “” EX 1 NX    //userid为1234的用户一秒钟内第二次下单，结果不成功
(nil)
redis> set createorder|userid|1234 “” EX 1 NX    //userid为1234的用户超过一秒钟再次下单，结果成功
"OK"
```

##### 消息队列

Redis可以通过list数据结构实现消息队列的功能，这样可以在电商秒杀，或者在线教育集中约课等高并发写场景下，提供消峰功能。方法：RPUSH/LPOP` 或者 `LPUSH/RPOP

##### 浏览器历史记录

每当我们访问一个新的网页，浏览器就会自动存储下来，当我们点击“后退”按钮时，最近一次访问的网页就会展示出来。我们可以通过Redis list来实现栈功能，进而实现浏览器历史记录场景。

##### 分布式锁

```php
redis> set mytasklock “tony” ex 10 nx    //获取分布式锁成功，加锁人为tony，过期时间为10秒
"OK"
redis> set mytasklock “tom” ex 10 nx    //获取分布式锁失败，加锁人为tom
(nil)
redis> del mytasklock    //释放分布式锁
(integer) 1              //该步骤需要通过lua脚本实现原子性操作——“如果加锁人为tony，则释放锁”

//缺点：不可重入，无法续期
```

##### 用户签到

适合Redis BitMap数据结构，通过其bit位来进行状态存储

![img](https://gitee.com/xu_zuyun/picgo/raw/master/img/a5461129920443baa3654db734c6914d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

##### 网站UV统计

通过Redis Set存储用户ID的方式进行解决，非常耗费内存空间。这时，Redis HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%，但仅仅占用12k的内存空间。

### 11、问题

##### 1、如何保证数据双写一致？

双写一致性问题指的是当系统同时对缓存和数据库进行写操作时，需要保持两者数据的一致性。

![image.png](https://gitee.com/xu_zuyun/picgo/raw/master/img/b2576e79acb3443a9190103bac419723~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp)

**消息队列 + 延迟双删策略**

1. 删除缓存
2. 更新数据库
3. 延迟一会再删除缓存（消息队列允许我们安排一个未来某个时间点执行的任务，在这种情况下就是延迟删除缓存）

即使因为并发问题保存了旧值，但延迟一段时间之后旧值就会被删除，那么这样就自然而然的保证了数据库和缓存的最终一致性。

```
第一次删除是为了尽快从缓存中移除可能过时的数据条目。在数据库更新之前执行这一步骤可以防止应用程序在数据更新期间读取到旧数据。
在第一次删除和数据库更新之间可能仍然存在一个非常小的时间窗口，在这个窗口期内，其他进程或线程可能查询数据并将旧数据重新写入到缓存中。因此，延迟双删策略中建议进行第二次删除，以处理可能在第一轮操作中遗漏的数据不一致问题。
```

##### 2、经常变动的信息, 为什么存在哈希表？

**高效的字段更新**：如果你的数据包含多个字段，并且这些字段可能独立地频繁更新，使用哈希可以让你只修改目标字段而不是替换整个对象。

**空间节省**：当存储相似结构的多个对象时，与为每个字段单独设置一个键相比，将它们组合在一个哈希键中通常更节省空间。

**便于获取部分信息**：你可以只获取哈希中的一些字段，无需读取整个结构。

```bash
# 创建或更新用户的姓名和邮箱
HSET user:1000 name "John Doe" email "john@example.com"

# 只更新用户的邮箱
HSET user:1000 email "john.doe@example.com"

# 获取用户的全部信息
HGETALL user:1000

# 获取用户的姓名
HGET user:1000 name
```

##### 3、lua脚本为什么能保证原子性？

**单线程模型**：Redis 采用单线程模型来处理命令，这意味着任何给定时间内只有一个命令在执行。即使是具有并发客户端的情况，命令也总是逐一顺序执行的。因此，一旦 Lua 脚本开始执行，就没有其他命令能够在它完成之前运行。

**无抢占**：Redis 的事件循环不允许抢占。这表示一旦一个操作（比如 Lua 脚本）开始执行，它会持续到完成，不会被其他操作打断。
